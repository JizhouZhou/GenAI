{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae279a9a-2c3f-4ebc-a47a-c462968ad3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import *\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e373698-119a-4a01-8f07-87d62dc4e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crsp rows: 2704599\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare CRSP monthly data\n",
    "crsp = pd.read_parquet('./data/WRDS/crsp_m.parquet')\n",
    "crsp['prc'] = abs(crsp['prc'])\n",
    "crsp['ME'] = crsp['prc'] * crsp['shrout']  # Market equity\n",
    "crsp.sort_values(by=['permno', 'YearMonth'], inplace=True)\n",
    "crsp['bh1m'] = crsp.groupby('permno')['retadj'].shift(-1)  # Buy-and-hold return next month\n",
    "crsp['prc_l1'] = crsp.groupby('permno')['prc'].shift(1)    # Lagged price\n",
    "crsp.duplicated(subset=['permno','YearMonth']).sum()\n",
    "print(\"crsp rows:\", crsp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20248e1f-3489-4dc9-80aa-0118b72d4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare IBES actual EPS data\n",
    "EPS_true = pd.read_stata('./data/WRDS/EPS_unadjusted_actual_full.dta')\n",
    "EPS_true['YearMonth'] = EPS_true['ANNDATS'] + MonthEnd(0)\n",
    "EPS_true['EPS_true'] = EPS_true['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9631dd66-980f-41c0-83ec-bac661d9c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into quarterly and annual EPS\n",
    "EPS_true_qtr = EPS_true[EPS_true['PDICITY'] == 'QTR'].sort_values(by=['TICKER','PENDS'])\n",
    "EPS_true_ann = EPS_true[EPS_true['PDICITY'] == 'ANN'].sort_values(by=['TICKER','PENDS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecf96f4-8ebb-4caf-accd-217f36685ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag EPS and announcement dates\n",
    "EPS_true_qtr['EPS_true_l1'] = EPS_true_qtr.groupby('TICKER')['EPS_true'].shift(1)\n",
    "EPS_true_qtr['ANNDATS_l1'] = EPS_true_qtr.groupby('TICKER')['ANNDATS'].shift(1)\n",
    "EPS_true_ann['EPS_true_l1'] = EPS_true_ann.groupby('TICKER')['EPS_true'].shift(1)\n",
    "EPS_true_ann['ANNDATS_l1'] = EPS_true_ann.groupby('TICKER')['ANNDATS'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475b7ba5-7028-42d9-a061-d9ad8a7be159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IBES consensus forecasts and merge with actuals\n",
    "consensus = pd.read_parquet('./data/WRDS/EPS_summary.parquet')\n",
    "consensus['YearMonth'] = consensus['STATPERS'] + MonthEnd(0)\n",
    "consensus['EPS_ana'] = consensus['MEANEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6fc218b-942d-4d08-bd5a-9c16c99e5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into quarterly and annual forecasts\n",
    "consensus_quarter = consensus[consensus.FPI.isin(['6','7','8'])].copy()\n",
    "consensus_annual = consensus[consensus.FPI.isin(['1','2'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dae2156-add1-4cca-be6d-67e455240c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consensus_quarter after merge rows: 7035910\n"
     ]
    }
   ],
   "source": [
    "# Merge with actual EPS (quarterly)\n",
    "consensus_quarter = consensus_quarter.merge(\n",
    "    EPS_true_qtr[['TICKER','PENDS','EPS_true','ANNDATS','ANNDATS_l1','EPS_true_l1']], \n",
    "    left_on=['TICKER','FPEDATS'], \n",
    "    right_on=['TICKER','PENDS']\n",
    ")\n",
    "print(\"consensus_quarter after merge rows:\", consensus_quarter.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee10b41c-00d2-4273-b375-0a944be6ed24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consensus_annual after merge rows: 11758331\n"
     ]
    }
   ],
   "source": [
    "# Merge with actual EPS (annual)\n",
    "consensus_annual = consensus_annual.merge(\n",
    "    EPS_true_ann[['TICKER','PENDS','EPS_true','ANNDATS','ANNDATS_l1','EPS_true_l1']], \n",
    "    left_on=['TICKER','FPEDATS'], \n",
    "    right_on=['TICKER','PENDS']\n",
    ")\n",
    "print(\"consensus_annual after merge rows:\", consensus_annual.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e82ff1f4-9c12-46d4-8fbc-86f9215c69e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consensus combined rows: 18794241\n"
     ]
    }
   ],
   "source": [
    "# Combine the two\n",
    "consensus = pd.concat([consensus_quarter, consensus_annual], axis=0)\n",
    "print(\"consensus combined rows:\", consensus.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c0235d-e882-4803-b405-3c44cd134fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iclink rows: 29751\n"
     ]
    }
   ],
   "source": [
    "# Load and clean CRSP-IBES link table\n",
    "iclink = pd.read_csv('./data/WRDS/iclink_WRDS.csv')\n",
    "iclink.columns = ['ticker','permno','ncusip','sdate','edate','score']\n",
    "iclink['sdate'] = pd.to_datetime(iclink['sdate'])\n",
    "iclink['edate'] = pd.to_datetime(iclink['edate'])\n",
    "iclink.dropna(subset=['permno'], inplace=True)\n",
    "print(\"iclink rows:\", iclink.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55620e6f-c424-4e65-a783-35922a185961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 initial rows: 6261065\n"
     ]
    }
   ],
   "source": [
    "# Process FPI = 1 (annual forecast)\n",
    "a1 = consensus[consensus['FPI'] == '1'][['TICKER', 'STATPERS', 'FPEDATS', 'ANNDATS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS_l1']].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "print(\"a1 initial rows:\", a1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473d46fb-0b3b-4838-9cf5-3cfc1b99fb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 after link merge rows: 3138358\n"
     ]
    }
   ],
   "source": [
    "# Merge with CRSP-IBES link and filter by valid dates\n",
    "a1 = a1.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "print(\"a1 after link merge rows:\", a1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f242f1-b303-4f30-8b16-8836faf57e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 after date filter rows: 1867422\n"
     ]
    }
   ],
   "source": [
    "a1 = a1[(a1['STATPERS'] >= a1['sdate']) & (a1['STATPERS'] <= a1['edate'])]\n",
    "print(\"a1 after date filter rows:\", a1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8c06ab7-adde-4f44-b6bf-27f35ff40b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 after EPS_true cfacshr merge rows: 1491868\n"
     ]
    }
   ],
   "source": [
    "# Adjust EPS using cfacshr at announcement date\n",
    "a1['ANN_m'] = a1['ANNDATS'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'], right_on=['permno', 'YearMonth'])\n",
    "print(\"a1 after EPS_true cfacshr merge rows:\", a1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc711d75-20c8-4030-86bb-43affdfa3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 after EPS_true_l1 cfacshr merge rows: 1491868\n"
     ]
    }
   ],
   "source": [
    "a1['EPS_true'] = a1['EPS_true'] / a1['cfacshr']\n",
    "a1.drop(columns=['YearMonth', 'cfacshr'], inplace=True)\n",
    "\n",
    "# Adjust lagged EPS\n",
    "a1['ANN_m'] = a1['ANNDATS_l1'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'], right_on=['permno', 'YearMonth'],\n",
    "              how='left')\n",
    "print(\"a1 after EPS_true_l1 cfacshr merge rows:\", a1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da7b2cad-49d1-4736-9c57-6d0b38f44736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 after final cfacshr merge rows: 1490170\n"
     ]
    }
   ],
   "source": [
    "a1['cfacshr'] = pd.to_numeric(a1['cfacshr'], errors='coerce')\n",
    "a1['EPS_true_l1'] = pd.to_numeric(a1['EPS_true_l1'], errors='coerce')\n",
    "a1['EPS_true_l1'] = a1['EPS_true_l1'] / a1['cfacshr']\n",
    "a1.drop(columns=['YearMonth', 'cfacshr', 'sdate', 'edate', 'ANN_m'], inplace=True)\n",
    "\n",
    "# Adjust both EPS to current cfacshr at STATPERS date\n",
    "a1['YearMonth'] = a1['STATPERS'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno', 'YearMonth', 'cfacshr', 'ncusip']], on=['permno', 'YearMonth'])\n",
    "print(\"a1 after final cfacshr merge rows:\", a1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e26a76b8-d3ba-4f85-82a6-18fa5c1c8c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 after CUSIP match rows: 1486269\n"
     ]
    }
   ],
   "source": [
    "a1['EPS_true'] = a1['EPS_true'] * a1['cfacshr']\n",
    "a1['EPS_true_l1'] = a1['EPS_true_l1'] * a1['cfacshr']\n",
    "\n",
    "# Keep observations where CUSIP matches\n",
    "a1 = a1[a1['CUSIP'] == a1['ncusip']].copy()\n",
    "print(\"a1 after CUSIP match rows:\", a1.shape[0])\n",
    "\n",
    "a1.rename(columns={'EPS_true_l1': 'EPS_true_l1_y1', \n",
    "                   'EPS_true': 'EPS_true_y1', \n",
    "                   'EPS_ana': 'EPS_ana_y1', \n",
    "                   'ANNDATS': 'ANNDATS_y1', \n",
    "                   'ANNDATS_l1': 'ANNDATS_l1_y1'}, inplace=True)\n",
    "\n",
    "a1.drop(columns=['cfacshr', 'ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fa666-639b-488d-9c50-19e3e5000495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adf062-139e-4ed5-b9fc-e1531f518e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc859f2-0446-4d1f-9985-12470393f273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02b6142e-cf98-4826-9852-67ebb8ac8061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         TICKER   STATPERS    FPEDATS ANNDATS_y1     CUSIP  EPS_ana_y1  \\\n",
       "0         0000 2014-04-17 2014-12-31 2015-01-30  87482X10        0.52   \n",
       "1         0000 2014-05-15 2014-12-31 2015-01-30  87482X10        0.56   \n",
       "2         0000 2014-06-19 2014-12-31 2015-01-30  87482X10        0.56   \n",
       "3         0000 2014-07-17 2014-12-31 2015-01-30  87482X10        0.56   \n",
       "4         0000 2014-08-14 2014-12-31 2015-01-30  87482X10        1.18   \n",
       "...        ...        ...        ...        ...       ...         ...   \n",
       "1490165   ZYNX 2022-10-20 2022-12-31 2023-03-13  98986M10        0.43   \n",
       "1490166   ZYNX 2022-11-17 2022-12-31 2023-03-13  98986M10        0.43   \n",
       "1490167   ZYNX 2022-12-15 2022-12-31 2023-03-13  98986M10        0.43   \n",
       "1490168   ZYNX 2023-01-19 2022-12-31 2023-03-13  98986M10        0.43   \n",
       "1490169   ZYNX 2023-02-16 2022-12-31 2023-03-13  98986M10        0.43   \n",
       "\n",
       "         EPS_true_y1  EPS_true_l1_y1 ANNDATS_l1_y1 ticker   permno  score  \\\n",
       "0               1.21             NaN    2014-02-14   0000  14471.0      1   \n",
       "1               1.21             NaN    2014-02-14   0000  14471.0      1   \n",
       "2               1.21             NaN    2014-02-14   0000  14471.0      1   \n",
       "3               1.21             NaN    2014-02-14   0000  14471.0      1   \n",
       "4               1.21             NaN    2014-02-14   0000  14471.0      1   \n",
       "...              ...             ...           ...    ...      ...    ...   \n",
       "1490165         0.44            0.44    2022-02-24   ZYNX  18418.0      1   \n",
       "1490166         0.44            0.44    2022-02-24   ZYNX  18418.0      1   \n",
       "1490167         0.44            0.44    2022-02-24   ZYNX  18418.0      1   \n",
       "1490168         0.44            0.44    2022-02-24   ZYNX  18418.0      1   \n",
       "1490169         0.44            0.44    2022-02-24   ZYNX  18418.0      1   \n",
       "\n",
       "         YearMonth  \n",
       "0       2014-04-30  \n",
       "1       2014-05-31  \n",
       "2       2014-06-30  \n",
       "3       2014-07-31  \n",
       "4       2014-08-31  \n",
       "...            ...  \n",
       "1490165 2022-10-31  \n",
       "1490166 2022-11-30  \n",
       "1490167 2022-12-31  \n",
       "1490168 2023-01-31  \n",
       "1490169 2023-02-28  \n",
       "\n",
       "[1486269 rows x 13 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e31505-fa0a-4ef8-9951-bf690007d6e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: EPS_ana'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Winsorize EPS forecast and actual values (monthly basis)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m a1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPS_ana\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43ma1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYearMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEPS_ana\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\\\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mclip(x\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.01\u001b[39m), x\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.99\u001b[39m)))\n\u001b[1;32m      4\u001b[0m a1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPS_true\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m a1\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYearMonth\u001b[39m\u001b[38;5;124m'\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPS_true\u001b[39m\u001b[38;5;124m'\u001b[39m]\\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mclip(x\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.01\u001b[39m), x\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.99\u001b[39m)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Rename columns to indicate FPI = 1 forecast\u001b[39;00m\n",
      "File \u001b[0;32m~/PyVENV/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyVENV/lib/python3.9/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: EPS_ana'"
     ]
    }
   ],
   "source": [
    "# Winsorize EPS forecast and actual values (monthly basis)\n",
    "a1['EPS_ana'] = a1.groupby('YearMonth', group_keys=False)['EPS_ana']\\\n",
    "    .transform(lambda x: x.clip(x.quantile(0.01), x.quantile(0.99)))\n",
    "a1['EPS_true'] = a1.groupby('YearMonth', group_keys=False)['EPS_true']\\\n",
    "    .transform(lambda x: x.clip(x.quantile(0.01), x.quantile(0.99)))\n",
    "\n",
    "# Rename columns to indicate FPI = 1 forecast\n",
    "a1.rename(columns={\n",
    "    'EPS_true_l1': 'EPS_true_l1_y1',\n",
    "    'EPS_true': 'EPS_true_y1',\n",
    "    'EPS_ana': 'EPS_ana_y1',\n",
    "    'ANNDATS': 'ANNDATS_y1',\n",
    "    'ANNDATS_l1': 'ANNDATS_l1_y1'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04d22e-d716-4842-abbe-f5a42a9c4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_cleaned = a1.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d581307-58b8-47d1-a40c-6c99680dba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_all = reduce(lambda x, y: pd.merge(x, y,\n",
    "                                       on=['permno', 'YearMonth'],\n",
    "                                       how='outer'),\n",
    "                 [a1_cleaned])\n",
    "\n",
    "df = ana_all.merge(crsp[['permno','YearMonth','siccd',\n",
    "                         'ret', 'prc', 'bh1m', 'shrout', 'ME','prc_l1'\n",
    "                        ]],\n",
    "                   on=['permno','YearMonth'], \n",
    "                   )\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load and prepare WRDS financial ratio data\n",
    "# ------------------------------------------------------\n",
    "ratios = pd.read_stata('./data/WRDS/financial_ratio.dta')\n",
    "\n",
    "# Align the public date to the end of the month\n",
    "ratios['public_date'] = ratios['public_date'] + MonthEnd(0)\n",
    "\n",
    "# Ensure gvkey is float for consistency\n",
    "ratios['gvkey'] = ratios['gvkey'].astype(float)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load and prepare Compustat data (used for SIC codes)\n",
    "# ------------------------------------------------------\n",
    "compa = pd.read_parquet('./data/WRDS/compa.parquet')\n",
    "compa['gvkey'] = compa['gvkey'].astype(float)\n",
    "\n",
    "# Merge SIC code from Compustat into financial ratios\n",
    "ratios = ratios.merge(\n",
    "    compa[['gvkey', 'datadate', 'sich']],\n",
    "    left_on=['gvkey', 'adate'],\n",
    "    right_on=['gvkey', 'datadate'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Merge financial ratios into main dataframe (df)\n",
    "# ------------------------------------------------------\n",
    "df = df.merge(\n",
    "    ratios,\n",
    "    left_on=['permno', 'YearMonth'],\n",
    "    right_on=['permno', 'public_date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Assign a SIC code using either Compustat (sich) or CRSP (siccd)\n",
    "# ------------------------------------------------------\n",
    "df['sic'] = np.where(df['sich'].isna(), df['siccd'], df['sich'])\n",
    "df['sic'] = df['sic'].astype(int)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Load Fama-French 49 industry classification\n",
    "# ------------------------------------------------------\n",
    "fama49 = pd.read_csv('./data/Other/Siccodes49.csv')\n",
    "\n",
    "# Helper function: convert SIC ranges (start, end) to list of individual SICs\n",
    "def zip_2_list(pairs):\n",
    "    result = []\n",
    "    for start, end in pairs:\n",
    "        result.extend(range(start, end))\n",
    "    return result\n",
    "\n",
    "# Group SIC ranges by FF49 industry and convert to full SIC lists\n",
    "fama49 = fama49.groupby('ff49').apply(lambda x: zip_2_list(zip(x.sic1, x.sic2 + 1)))\n",
    "\n",
    "# Function to assign FF49 industry based on SIC\n",
    "def fama_industry(sic, fama_dict):\n",
    "    for ff49, sics in fama_dict.items():\n",
    "        if sic in sics:\n",
    "            return ff49\n",
    "    return 49  # Default to \"Other\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Map each SIC in df to an FF49 industry\n",
    "# ------------------------------------------------------\n",
    "unique_sics = df['sic'].unique()\n",
    "sic_to_ff49 = pd.DataFrame({'sic': unique_sics})\n",
    "sic_to_ff49['fama49'] = sic_to_ff49['sic'].apply(lambda x: fama_industry(x, fama49))\n",
    "\n",
    "# Merge FF49 codes back into the main dataframe\n",
    "df = df.merge(sic_to_ff49, how='left', on='sic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af427c2-1c21-417a-bdae-e0680d699b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df pre-merge:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335fd0e-c890-4431-90c7-a3a5129f79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NA with Industry Median\n",
    "## preprocess \n",
    "ratio_chars = ['CAPEI', 'bm',\n",
    "       'evm', 'pe_exi', 'pe_inc', 'ps', 'pcf',\n",
    "       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe',\n",
    "       'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt',\n",
    "       'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "       'divyield']\n",
    "\n",
    "## XX per share characteristics: IN Online Appendix A.2, BHL states that they \"consider another twenty-six \n",
    "# fundamental values per share derived from these financial ratios\"\n",
    "# We recover these features from their persudo-data shared in RFS code & data\n",
    "# See the data they shared: \"/Earnings Forecasts/SampleFigure1.csv\". Columns 'BU' to 'CR', totaling 24\n",
    "# I add \"sales_p\" & \"invcap_p\" to make it 26\n",
    "per_share_chars = ['dividend_p','BE_p','Liability_p','cur_liability_p','LT_debt_p',\n",
    "                   'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', \n",
    "                   'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p',\n",
    "                   'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p',\n",
    "                   'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p','ptpm_p'\n",
    "                  ]\n",
    "\n",
    "df['dividend_p'] = df['divyield'] * df['prc']\n",
    "df['BE_p'] = df['bm'] * df['prc'] # book-equity\n",
    "df['Liability_p'] = df['de_ratio'] * df['BE_p'] # Total Debt\n",
    "df['cur_liability_p'] = df['curr_debt'] * df['Liability_p']\n",
    "df['LT_debt_p'] = df['lt_debt'] * df['Liability_p']\n",
    "df['cash_p'] = df['cash_lt'] * df['Liability_p']\n",
    "df['total_asset_p'] = df['Liability_p'] / df['debt_at']\n",
    "df['tot_debt_p'] = df['debt_assets'] * df['total_asset_p']\n",
    "df['accrual_p'] = df['accrual'] * df['total_asset_p']\n",
    "df['EBIT_p'] = df['debt_ebitda'] / df['tot_debt_p']\n",
    "df['cur_asset_p'] = df['curr_ratio']*df['cur_liability_p']\n",
    "df['pbda_p'] = df['profit_lct'] * df['cur_liability_p'] # Operating Income before D&A\n",
    "df['ocf_p'] = df['ocf_lct'] * df['cur_liability_p'] # Operating Cash Flow\n",
    "df['inventory_p'] = df['invt_act'] * df['cur_asset_p']\n",
    "df['receivables_p'] = df['rect_act'] * df['cur_asset_p']\n",
    "df['Cur_debt_p'] = df['short_debt'] * df['total_asset_p'] # Short-term Debt\n",
    "df['interest_p'] = df['int_totdebt'] * df['tot_debt_p']\n",
    "df['fcf_ocf_p'] = df['fcf_ocf'] * df['ocf_p'] # Free Cash Flow\n",
    "df['evm_p'] = df['evm'] * df['EBIT_p'] # Multiple of Enterprise Value\n",
    "\n",
    "## ADD by YANDI ##\n",
    "df['sales_p'] = df['sale_equity'] * df['BE_p'] # Sales\n",
    "df['invcap_p'] = df['debt_invcap'] / df['LT_debt_p'] # Invested Capital\n",
    "\n",
    "## Recover theirs\n",
    "df['c_equity_p'] = df['equity_invcap'] * df['invcap_p'] # Common Equity\n",
    "df['rd_p'] = df['rd_sale'] * df['sales_p'] # R&D\n",
    "df['opmad_p'] = df['opmad'] * df['sales_p'] # Operating Income After Depreciation\n",
    "df['gpm_p'] = df['gpm']  * df['sales_p'] # Gross Profit\n",
    "df['ptpm_p'] = df['ptpm']  * df['sales_p'] # Pretax Income\n",
    "\n",
    "df.replace([-np.inf, np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ca2d4-9715-4cf9-baa8-6ac09db5b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Your existing code here\n",
    "for v in tqdm(ratio_chars+per_share_chars):\n",
    "    df[v] = df.groupby(['YearMonth','fama49'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "for v in tqdm(ratio_chars+per_share_chars):\n",
    "    df[v] = df.groupby(['YearMonth'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18246d4e-59b4-4623-a107-45a240112771",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Macro Data\n",
    "RGDP = pd.read_excel('./data/Macro/RGDP.xlsx').set_index('DATE')\n",
    "RGDP = RGDP.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "RGDP.index = pd.date_range(start='1965-11', end='2024-04', freq='M')\n",
    "\n",
    "RCON = pd.read_excel('./data/Macro/RCON.xlsx').set_index('DATE')\n",
    "RCON = RCON.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "RCON.index = pd.date_range(start='1965-11', end='2024-04', freq='M')\n",
    "\n",
    "INDPROD = pd.read_excel('./data/Macro/INDPROD.xlsx').set_index('DATE')\n",
    "INDPROD = INDPROD.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "INDPROD.index = pd.date_range(start='1962-11', end='2024-03', freq='M')\n",
    "\n",
    "UNEMP = pd.read_excel('./data/Macro/UNEMP.xlsx').set_index('DATE')\n",
    "UNEMP = UNEMP['RUC24Q1'].dropna()\n",
    "UNEMP.index = pd.date_range(start='1948-01', end='2024-02', freq='M')\n",
    "## LAG one month, we can only observe last month UNEMP\n",
    "UNEMP = UNEMP.shift(1)\n",
    "\n",
    "macro = pd.DataFrame({'RGDP':RGDP,'RCON':RCON,'INDPROD':INDPROD,'UNEMP':UNEMP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947d751-5090-45cd-a22c-7fd4aa1aebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(macro, left_on='YearMonth', right_index=True)\n",
    "print(\"df macro-merge:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1753155-cc35-49a9-baaa-1fb2f3afb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f93ed-67f7-48a4-b4ff-403da51c54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_chars = ['CAPEI', 'bm',\n",
    "       'evm', 'pe_exi', 'pe_inc', 'ps', 'pcf',\n",
    "       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe',\n",
    "       'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt',\n",
    "       'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "       'divyield']\n",
    "\n",
    "per_share_chars = ['dividend_p','BE_p','Liability_p','cur_liability_p','LT_debt_p',\n",
    "                  'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', \n",
    "                   'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p',\n",
    "                   'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p',\n",
    "                   'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p','ptpm_p'\n",
    "                  ]\n",
    "\n",
    "macro_chars = ['RGDP', 'RCON', 'INDPROD', 'UNEMP']\n",
    "\n",
    "fundamental_chars = ['ret', 'prc',\n",
    "                    'EPS_true_l1_q1','EPS_true_l1_q2','EPS_true_l1_q3',\n",
    "                    'EPS_true_l1_y1','EPS_true_l1_y2',\n",
    "                    ]\n",
    "\n",
    "analyst_chars = ['EPS_ana_q1','EPS_ana_q2','EPS_ana_q3','EPS_ana_y1','EPS_ana_y2']\n",
    "\n",
    "targets = ['EPS_true_q1', 'EPS_true_q2', 'EPS_true_q3', 'EPS_true_y1', 'EPS_true_y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ea558-85bd-4967-b947-8cc505d03953",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lag one month information ###\n",
    "### Except for analyst forecasts\n",
    "df.sort_values(by=['permno', 'YearMonth'], inplace=True)\n",
    "# Filter vars_lag to only those columns that exist in df\n",
    "vars_lag = [v for v in ratio_chars + per_share_chars + macro_chars + fundamental_chars if v in df.columns]\n",
    "\n",
    "# Then apply the shift\n",
    "df[vars_lag] = df.groupby('permno')[vars_lag].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357d556-8bc8-4edf-aa57-94c8f09aa74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ## FillNA with Industry Median\n",
    "fillNA = ratio_chars + per_share_chars + fundamental_chars\n",
    "for v in tqdm(fillNA):\n",
    "    df[v] = df.groupby(['YearMonth','fama49'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))\n",
    "## In case some characteristics are all NA in some industry\n",
    "for v in tqdm(fillNA + macro_chars):\n",
    "    df[v] = df.groupby(['YearMonth'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ddbfa-8cf8-4c9d-a28f-151b8b63da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df[(df['YearMonth'] >= '1984-01-01') & (df['YearMonth'] <= '2019-12-31')].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18446080-6cc0-4b36-b1a0-36355581363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorization period-by-period\n",
    "cols = ratio_chars + per_share_chars + fundamental_chars\n",
    "df_tmp[cols] = df_tmp.groupby('YearMonth',group_keys=False)[cols]\\\n",
    "                             .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80036a74-485e-4c32-a982-5e01472599e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.to_parquet('./data/Results/df_train_new.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53ecbc-3093-43d5-8f58-6d312e44e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.to_cvs('./data/Results/df_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deaf20b3-861d-444f-bce1-fc17307a8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 110212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_stata('./data/Results/df_train_a1_U.dta')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df['fpedats'] = pd.to_datetime(df['fpedats'])\n",
    "df['statpers'] = pd.to_datetime(df['statpers'])\n",
    "\n",
    "# Keep only statpers strictly after fpedats and within 45 days\n",
    "df_filtered = df[(df['statpers'] > df['fpedats']) & \n",
    "                 (df['statpers'] <= df['fpedats'] + pd.Timedelta(days=45))]\n",
    "\n",
    "# Sort by statpers to identify the first one after fpedats\n",
    "df_first = df_filtered.sort_values(['permno', 'fpedats', 'statpers']).groupby(\n",
    "    ['permno', 'fpedats'], as_index=False).first()\n",
    "\n",
    "# Print number of rows\n",
    "print(f\"Number of rows: {len(df_first)}\")\n",
    "\n",
    "# Save the result\n",
    "df_first.to_stata('./data/Results/df_train_a1_U_45d.dta', write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03dc9fba-4181-4c7e-a94b-2b0b3c904e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates based on (permno, fpedats):\n",
      "Empty DataFrame\n",
      "Columns: [permno, fpedats, v1, statpers, eps_ana_y1, eps_true_y1, eps_true_l1_y1, anndats_y1, anndats_l1_y1, yearmonth, siccd, ret, prc, bh1m, shrout, me, prc_l1, gvkey, adate, qdate, public_date, capei, bm, evm, pe_op_basic, pe_op_dil, pe_exi, pe_inc, ps, pcf, dpr, npm, opmbd, opmad, gpm, ptpm, cfm, roa, roe, roce, efftax, aftret_eq, aftret_invcapx, aftret_equity, pretret_noa, pretret_earnat, gprof, equity_invcap, debt_invcap, totdebt_invcap, capital_ratio, int_debt, int_totdebt, cash_lt, invt_act, rect_act, debt_at, debt_ebitda, short_debt, curr_debt, lt_debt, profit_lct, ocf_lct, cash_debt, fcf_ocf, lt_ppent, dltt_be, debt_assets, debt_capital, de_ratio, intcov, intcov_ratio, cash_ratio, quick_ratio, curr_ratio, cash_conversion, inv_turn, at_turn, rect_turn, pay_turn, sale_invcap, sale_equity, sale_nwc, rd_sale, adv_sale, staff_sale, accrual, ptb, peg_trailing, divyield, peg_1yrforward, peg_ltgforward, ticker, cusip, datadate, sich, sic, fama49, dividend_p, be_p, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates based on (permno, fpedats)\n",
    "duplicates = df_first[df_first.duplicated(subset=['permno', 'fpedats'], keep=False)]\n",
    "\n",
    "# Print duplicates\n",
    "print(\"Duplicates based on (permno, fpedats):\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744b9d24-8c78-4666-bf81-13d428431bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicate rows: {len(duplicates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33981e-4c56-4776-873c-efa716e6dc6f",
   "metadata": {},
   "source": [
    "# 45 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d543c95-6c55-40e7-bf26-5fe4a4799316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 111779\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_stata('./data/Results/df_train_a1_U.dta')\n",
    "\n",
    "# Convert datetime columns and strip time to keep only date\n",
    "df['anndats_l1_y1'] = pd.to_datetime(df['anndats_l1_y1']).dt.normalize()\n",
    "df['statpers'] = pd.to_datetime(df['statpers']).dt.normalize()\n",
    "df['fpedats'] = pd.to_datetime(df['fpedats']).dt.normalize()\n",
    "\n",
    "df_filtered = df[\n",
    "    (df['statpers'] > df['anndats_l1_y1']) &\n",
    "    (df['statpers'] <= df['anndats_l1_y1'] + pd.Timedelta(days=45))\n",
    "].copy()\n",
    "\n",
    "# Now safely add the new column\n",
    "df_filtered['diff_days'] = (df_filtered['statpers'] - df_filtered['anndats_l1_y1']).dt.days\n",
    "\n",
    "# Keep the first statpers within that window for each (permno, anndats_l1_y1)\n",
    "df_first = df_filtered.sort_values(['permno', 'anndats_l1_y1', 'statpers']).groupby(\n",
    "    ['permno', 'anndats_l1_y1'], as_index=False).first()\n",
    "\n",
    "# Print number of rows\n",
    "print(f\"Number of rows: {len(df_first)}\")\n",
    "\n",
    "# Save the output\n",
    "df_first.to_stata('./data/Results/df_train_a1_U_45d_after_anndats_y1_l1.dta', write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089731e8-bf45-4a2e-a345-64ac6df8d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['v1', 'statpers', 'fpedats', 'eps_ana_y1', 'eps_true_y1',\n",
      "       'eps_true_l1_y1', 'anndats_y1', 'anndats_l1_y1', 'permno', 'yearmonth',\n",
      "       ...\n",
      "       'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p', 'ptpm_p', 'rgdp',\n",
      "       'rcon', 'indprod', 'unemp'],\n",
      "      dtype='object', length=128)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6808538-b23e-4b89-bfec-09c8aa40cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    164944.000000\n",
      "mean         23.476574\n",
      "std          12.880020\n",
      "min           1.000000\n",
      "25%          14.000000\n",
      "50%          23.000000\n",
      "75%          35.000000\n",
      "max          45.000000\n",
      "Name: diff_days, dtype: float64\n",
      "diff_days\n",
      "1     5450\n",
      "2     5282\n",
      "3     2828\n",
      "4       23\n",
      "5      227\n",
      "6     2494\n",
      "7     5969\n",
      "8     5400\n",
      "9     5145\n",
      "10    3168\n",
      "11       8\n",
      "12     196\n",
      "13    2487\n",
      "14    5957\n",
      "15    5830\n",
      "16    6275\n",
      "17    4334\n",
      "18      15\n",
      "19     249\n",
      "20    3548\n",
      "21    8899\n",
      "22    7532\n",
      "23    7087\n",
      "24    3437\n",
      "25      58\n",
      "26     744\n",
      "27    2872\n",
      "28    6972\n",
      "29    6257\n",
      "30    5863\n",
      "31    2960\n",
      "32      59\n",
      "33     464\n",
      "34    2619\n",
      "35    6277\n",
      "36    5648\n",
      "37    5300\n",
      "38    3275\n",
      "39       2\n",
      "40     185\n",
      "41    2563\n",
      "42    5929\n",
      "43    5567\n",
      "44    5553\n",
      "45    3937\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_filtered['diff_days'].describe())\n",
    "print(df_filtered['diff_days'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac67ae-9d69-4539-888d-a672614912f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
