{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6484ccaf-53d9-4ba5-9c83-ec85d91644ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import *\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba9cf08-00cf-4d6e-b357-8f8ec5d46129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crsp = pd.read_parquet('./data/WRDS/crsp_m.parquet')\n",
    "crsp['prc'] = abs(crsp['prc'])\n",
    "crsp['ME'] = (crsp['prc']) * crsp['shrout']\n",
    "crsp.sort_values(by=['permno','YearMonth'], inplace=True)\n",
    "crsp['bh1m'] = crsp.groupby('permno')['retadj'].shift(-1)\n",
    "crsp['prc_l1'] = crsp.groupby('permno')['prc'].shift(1)\n",
    "crsp.duplicated(subset=['permno','YearMonth']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9114a7c-e48a-4892-a06e-b75ca8f31021",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IBES actual\n",
    "EPS_true = pd.read_stata('./data/WRDS/EPS_unadjusted_actual_full.dta')\n",
    "EPS_true['YearMonth'] = EPS_true['ANNDATS'] + MonthEnd(0)\n",
    "EPS_true['EPS_true'] = EPS_true['VALUE']\n",
    "\n",
    "# Last EPS\n",
    "EPS_true_qtr = EPS_true[EPS_true['PDICITY'] == 'QTR'].sort_values(by=['TICKER','PENDS'])\n",
    "EPS_true_ann = EPS_true[EPS_true['PDICITY'] == 'ANN'].sort_values(by=['TICKER','PENDS'])\n",
    "\n",
    "EPS_true_qtr['EPS_true_l1'] = EPS_true_qtr.groupby('TICKER')['EPS_true'].shift(1)\n",
    "EPS_true_qtr['ANNDATS_l1'] = EPS_true_qtr.groupby('TICKER')['ANNDATS'].shift(1)\n",
    "\n",
    "EPS_true_ann['EPS_true_l1'] = EPS_true_ann.groupby('TICKER')['EPS_true'].shift(1)\n",
    "EPS_true_ann['ANNDATS_l1'] = EPS_true_ann.groupby('TICKER')['ANNDATS'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4688c5ab-8f19-4169-9a63-f086fafab384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IBES consensus\n",
    "consensus = pd.read_parquet('./data/WRDS/EPS_summary.parquet')\n",
    "\n",
    "consensus['YearMonth'] = consensus['STATPERS'] + MonthEnd(0)\n",
    "consensus['EPS_ana'] = consensus['MEANEST']\n",
    "\n",
    "# Merge with Actual\n",
    "consensus_quarter = consensus[consensus.FPI.isin(['6','7','8'])].copy()\n",
    "consensus_annual = consensus[consensus.FPI.isin(['1','2'])].copy()\n",
    "\n",
    "consensus_quarter = consensus_quarter.merge(\n",
    "    EPS_true_qtr[['TICKER','PENDS','EPS_true','ANNDATS','ANNDATS_l1','EPS_true_l1']], \n",
    "    left_on=['TICKER','FPEDATS'], \n",
    "    right_on=['TICKER','PENDS']\n",
    ")\n",
    "\n",
    "consensus_annual = consensus_annual.merge(\n",
    "    EPS_true_ann[['TICKER','PENDS','EPS_true','ANNDATS','ANNDATS_l1','EPS_true_l1']], \n",
    "    left_on=['TICKER','FPEDATS'], \n",
    "    right_on=['TICKER','PENDS']\n",
    ")\n",
    "\n",
    "consensus = pd.concat([consensus_quarter, consensus_annual], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74616fb-c3be-4645-876f-7e1db4085803",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CRSP-IBES link table\n",
    "iclink = pd.read_csv('./data/WRDS/iclink_WRDS.csv')\n",
    "iclink.columns = ['ticker','permno','ncusip','sdate','edate','score']\n",
    "iclink['sdate'] = pd.to_datetime(iclink['sdate'])\n",
    "iclink['edate'] = pd.to_datetime(iclink['edate'])\n",
    "iclink.dropna(subset=['permno'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea5cd34-c861-4fbb-b89e-238bc13e678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter FPI == 1 and select relevant columns\n",
    "a1 = consensus[consensus['FPI'] == '1'][['TICKER', 'STATPERS', 'FPEDATS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "a1['horizon'] = 'a1'\n",
    "\n",
    "# Step 2: Merge with ICLINK\n",
    "a1 = a1.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "\n",
    "# Step 3: Filter by date range\n",
    "a1 = a1[(a1['STATPERS'] >= a1['sdate']) & (a1['STATPERS'] <= a1['edate'])]\n",
    "\n",
    "# Step 4: Merge cfacshr for ANNDATS\n",
    "a1['ANN_m'] = a1['ANNDATS'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'], right_on=['permno', 'YearMonth'])\n",
    "\n",
    "# Step 5: Adjust EPS_true\n",
    "a1['EPS_true'] = a1['EPS_true'] / a1['cfacshr']\n",
    "a1.drop(columns=['YearMonth', 'cfacshr'], inplace=True)\n",
    "\n",
    "# Step 6: Merge cfacshr for ANNDATS_l1\n",
    "a1['ANN_m'] = a1['ANNDATS_l1'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'], right_on=['permno', 'YearMonth'],\n",
    "              how='left')\n",
    "\n",
    "# Step 7: Adjust EPS_true_l1\n",
    "a1['cfacshr'] = pd.to_numeric(a1['cfacshr'], errors='coerce')\n",
    "a1['EPS_true_l1'] = pd.to_numeric(a1['EPS_true_l1'], errors='coerce')\n",
    "a1['EPS_true_l1'] = a1['EPS_true_l1'] / a1['cfacshr']\n",
    "a1.drop(columns=['YearMonth', 'cfacshr', 'sdate', 'edate', 'ANN_m'], inplace=True)\n",
    "\n",
    "# Step 8: Merge with current month cfacshr and ncusip\n",
    "a1['YearMonth'] = a1['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "a1 = a1.merge(crsp[['permno', 'YearMonth', 'cfacshr', 'ncusip']], on=['permno', 'YearMonth'])\n",
    "\n",
    "# Step 9: Re-adjust EPS values to current cfacshr\n",
    "a1['EPS_true'] = a1['EPS_true'] * a1['cfacshr']\n",
    "a1['EPS_true_l1'] = a1['EPS_true_l1'] * a1['cfacshr']\n",
    "\n",
    "# Step 10: Match CUSIP with ncusip\n",
    "a1 = a1[a1['CUSIP'] == a1['ncusip']].copy()\n",
    "\n",
    "# Step 11: Drop unused columns\n",
    "a1.drop(columns=['cfacshr', 'ncusip'], inplace=True)\n",
    "\n",
    "a1_cleaned = a1.drop(columns=['TICKER', 'CUSIP', 'score', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4506191-bef9-4758-a223-a48c386a4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a2 = consensus[consensus['FPI']=='2'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                       'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1',\n",
    "                                      ]].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "a2['horizon'] = 'a2'\n",
    "\n",
    "# ICLINK\n",
    "a2 = a2.merge(iclink[['ticker','permno','sdate','edate','score']], \n",
    "              left_on=['TICKER'],\n",
    "              right_on=['ticker'])\n",
    "a2 = a2[(a2['STATPERS'] >= a2['sdate']) & (a2['STATPERS'] <= a2['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "a2['ANN_m'] = a2['ANNDATS'] + MonthEnd(0)\n",
    "a2 = a2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'])\n",
    "a2['EPS_true'] = a2['EPS_true'] / a2['cfacshr']\n",
    "a2.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "a2['ANN_m'] = a2['ANNDATS_l1'] + MonthEnd(0)\n",
    "a2 = a2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              how='left')\n",
    "# Ensure cfacshr is numeric\n",
    "a2['cfacshr'] = pd.to_numeric(a2['cfacshr'], errors='coerce')\n",
    "a2['EPS_true_l1'] = pd.to_numeric(a2['EPS_true_l1'], errors='coerce')\n",
    "\n",
    "# Perform the division\n",
    "a2['EPS_true_l1'] = a2['EPS_true_l1'] / a2['cfacshr']\n",
    "a2.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "a2['YearMonth'] = a2['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "print(a2.duplicated(subset=['permno','STATPERS']).sum())\n",
    "\n",
    "a2 = a2.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "a2['EPS_true'] = a2['EPS_true'] * a2['cfacshr']\n",
    "a2['EPS_true_l1'] = a2['EPS_true_l1'] * a2['cfacshr']\n",
    "# cusip == ncusip\n",
    "a2 = a2[a2['CUSIP'] == a2['ncusip']].copy()\n",
    "a2.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bfd263-d8ef-4a4e-9a10-59f2edf7db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Manage forecast and actual\n",
    "q1 = consensus[consensus['FPI'] == '6'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']\n",
    "                                       ].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "q1['horizon'] = 'q1'\n",
    "\n",
    "# ICLINK\n",
    "q1 = q1.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "q1 = q1[(q1['STATPERS'] >= q1['sdate']) & (q1['STATPERS'] <= q1['edate'])]\n",
    "\n",
    "# Initial adjustment using ANNDATS\n",
    "q1['ANN_m'] = q1['ANNDATS'] + MonthEnd(0)\n",
    "q1 = q1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'],\n",
    "              right_on=['permno', 'YearMonth'])\n",
    "q1['EPS_true'] = q1['EPS_true'] / q1['cfacshr']\n",
    "q1.drop(columns=['YearMonth', 'cfacshr'], inplace=True)\n",
    "\n",
    "# Adjustment for EPS_true_l1 using ANNDATS_l1\n",
    "q1['ANN_m'] = q1['ANNDATS_l1'] + MonthEnd(0)\n",
    "q1 = q1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'],\n",
    "              right_on=['permno', 'YearMonth'],\n",
    "              how='left')\n",
    "q1['EPS_true_l1'] = q1.apply(\n",
    "    lambda row: row['EPS_true_l1'] / row['cfacshr'] if pd.notnull(row['cfacshr']) and row['cfacshr'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "q1.drop(columns=['YearMonth', 'cfacshr', 'sdate', 'edate', 'ANN_m'], inplace=True)\n",
    "\n",
    "# Today's adjustment\n",
    "q1['YearMonth'] = q1['STATPERS'] + MonthEnd(0)\n",
    "q1 = q1.merge(crsp[['permno', 'YearMonth', 'cfacshr', 'ncusip']], \n",
    "              on=['permno', 'YearMonth'])\n",
    "q1['EPS_true'] = q1['EPS_true'] * q1['cfacshr']\n",
    "q1['EPS_true_l1'] = q1['EPS_true_l1'] * q1['cfacshr']\n",
    "q1 = q1[q1['ncusip'] == q1['CUSIP']]\n",
    "q1.drop(columns=['cfacshr', 'ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f1035b-4ade-4686-8dfb-9c7c65fb0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = consensus[consensus['FPI'] == '7'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']\n",
    "                                       ].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "q2['horizon'] = 'q2'\n",
    "\n",
    "# ICLINK\n",
    "q2 = q2.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "\n",
    "q2 = q2[(q2['STATPERS']>=q2['sdate']) & (q2['STATPERS']<=q2['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "q2['ANN_m'] = q2['ANNDATS'] + MonthEnd(0)\n",
    "q2 = q2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "             )\n",
    "q2['EPS_true'] = q2['EPS_true']/q2['cfacshr']\n",
    "q2.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "q2['ANN_m'] = q2['ANNDATS_l1'] + MonthEnd(0)\n",
    "q2 = q2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "             how='left'\n",
    "             )\n",
    "\n",
    "q2['EPS_true_l1'] = q2.apply(\n",
    "    lambda row: row['EPS_true_l1'] / row['cfacshr'] if row['cfacshr'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "q2.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "q2['YearMonth'] = q2['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "q2 = q2.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "q2['EPS_true'] = q2['EPS_true'] * q2['cfacshr']\n",
    "q2['EPS_true_l1'] = q2['EPS_true_l1'] * q2['cfacshr']\n",
    "q2 = q2[q2['ncusip']==q2['CUSIP']]\n",
    "q2.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620b26ea-4f1c-4731-94c8-cf18d51ac8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = consensus[consensus['FPI']=='8'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']\n",
    "                                       ].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "q3['horizon'] = 'q3'\n",
    "\n",
    "# ICLINK\n",
    "q3 = q3.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "\n",
    "q3 = q3[(q3['STATPERS']>=q3['sdate']) & (q3['STATPERS']<=q3['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "q3['ANN_m'] = q3['ANNDATS'] + MonthEnd(0)\n",
    "q3 = q3.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              # how='left'\n",
    "             )\n",
    "# q3['cfacshr'] = q3.groupby('permno')['cfacshr'].ffill()\n",
    "q3['EPS_true'] = q3['EPS_true']/q3['cfacshr']\n",
    "q3.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "q3['ANN_m'] = q3['ANNDATS_l1'] + MonthEnd(0)\n",
    "q3 = q3.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              how='left'\n",
    "             )\n",
    "\n",
    "q3['EPS_true_l1'] = q3.apply(\n",
    "    lambda row: row['EPS_true_l1'] / row['cfacshr'] if row['cfacshr'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "q3.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "q3['YearMonth'] = q3['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "\n",
    "q3 = q3.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "q3['EPS_true'] = q3['EPS_true'] * q3['cfacshr']\n",
    "q3['EPS_true_l1'] = q3['EPS_true_l1'] * q3['cfacshr']\n",
    "q3 = q3[q3['CUSIP']==q3['ncusip']]\n",
    "q3.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e84709-d2fa-4545-8742-af76db654277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87843337-4613-4158-8e0d-72a135e4de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1['EPS_ana'] = a1.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a1['EPS_true'] = a1.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a1.rename(columns={'EPS_true_l1': 'EPS_true_l1_y1', \n",
    "                   'EPS_true': 'EPS_true_y1', \n",
    "                   'EPS_ana': 'EPS_ana_y1', \n",
    "                   'ANNDATS': 'ANNDATS_y1', \n",
    "                   'ANNDATS_l1': 'ANNDATS_l1_y1'}, inplace=True)\n",
    "a1_cleaned = a1.drop(columns=['TICKER', 'CUSIP', 'score', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dca7290-6dc4-440a-9b74-4a4e0ff53d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2['EPS_ana'] = a2.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a2['EPS_true'] = a2.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a2.rename(columns={'EPS_true_l1':'EPS_true_l1_y2',\n",
    "                   'EPS_true':'EPS_true_y2',\n",
    "                   'EPS_ana':'EPS_ana_y2',\n",
    "                   'ANNDATS':'ANNDATS_y2',\n",
    "                   'ANNDATS_l1':'ANNDATS_l1_y2'\n",
    "                  }, \n",
    "          inplace=True)\n",
    "a2_cleaned = a2.drop(columns=['TICKER', 'CUSIP', 'score', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d42450-c64a-4f18-ba13-964afa9cb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_cleaned = q1.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])\n",
    "q2_cleaned = q2.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])\n",
    "q3_cleaned = q3.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e93c91-2b2a-4b8f-964e-3d4201728cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_cleaned = q1_cleaned.rename(columns={'horizon': 'horizon_q1'})\n",
    "q2_cleaned = q2_cleaned.rename(columns={'horizon': 'horizon_q2'})\n",
    "q3_cleaned = q3_cleaned.rename(columns={'horizon': 'horizon_q3'})\n",
    "a1_cleaned = a1_cleaned.rename(columns={'horizon': 'horizon_a1'})\n",
    "a2_cleaned = a2_cleaned.rename(columns={'horizon': 'horizon_a2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "916b92c5-71ca-4c8a-85eb-6601dd705e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge without suffixes\n",
    "ana_all = reduce(lambda x, y: pd.merge(x, y,\n",
    "                                       on=['permno', 'YearMonth'],\n",
    "                                       how='outer'),\n",
    "                 [q1_cleaned, q2_cleaned, q3_cleaned, a1_cleaned, a2_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df0b09cf-1704-4490-aaa9-5f86ec3eecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ana_all.merge(crsp[['permno','YearMonth','siccd',\n",
    "                         'ret', 'prc', 'bh1m', 'shrout', 'ME','prc_l1'\n",
    "                        ]],\n",
    "                   on=['permno','YearMonth'], \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "521eefa4-d16b-46fc-b826-53e47c8b8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Financial Ratios ####\n",
    "ratios = pd.read_stata('./data/WRDS/financial_ratio.dta')\n",
    "ratios['public_date'] = ratios['public_date'] + MonthEnd(0)\n",
    "ratios['gvkey'] = ratios['gvkey'].astype(float)\n",
    "\n",
    "#### COMUPSTAT ####\n",
    "compa = pd.read_parquet('./data/WRDS/compa.parquet')\n",
    "compa['gvkey'] = compa['gvkey'].astype(float)\n",
    "\n",
    "## SIC code from Compustat\n",
    "ratios = ratios.merge(compa[['gvkey','datadate','sich']], \n",
    "                     left_on = ['gvkey','adate'],\n",
    "                     right_on = ['gvkey','datadate'],\n",
    "                     how = 'left'\n",
    "                    )\n",
    "\n",
    "df = df.merge(ratios, \n",
    "              left_on=['permno','YearMonth'], \n",
    "              right_on=['permno','public_date'],\n",
    "              how = 'left'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3777c26-92de-48a0-9313-4fccab29fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FF49 Industry\n",
    "def zip_2_list(x):\n",
    "    tmp = []\n",
    "    for i, j in x:\n",
    "        tmp += list(range(i,j))\n",
    "    return tmp\n",
    "\n",
    "def fama_industry(sic, fama10):\n",
    "    for i in fama10.index:\n",
    "        if sic in fama10[i]:\n",
    "            return i\n",
    "    ## others\n",
    "    return 49\n",
    "\n",
    "# If sich is missing, use siccd from CRSP\n",
    "df['sic'] = np.where(df['sich'].isna(), df['siccd'], df['sich'])\n",
    "df['sic'] = df['sic'].astype(int)\n",
    "\n",
    "fama49 = pd.read_csv('./data/Other/Siccodes49.csv')\n",
    "fama49 = fama49.groupby('ff49').apply(lambda x: zip_2_list(zip(x.sic1, x.sic2+1)))\n",
    "\n",
    "_sic = df['sic'].unique()\n",
    "_sicff = pd.DataFrame(_sic).rename(columns={0:'sic'})\n",
    "_sicff['fama49'] = _sicff['sic'].apply(lambda x: fama_industry(x,fama49))\n",
    "\n",
    "df = pd.merge(df, _sicff, how='left', on=['sic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20749d1e-ccb2-4861-ab88-2b533eefa658",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NA with Industry Median\n",
    "## preprocess \n",
    "ratio_chars = ['CAPEI', 'bm',\n",
    "       'evm', 'pe_exi', 'pe_inc', 'ps', 'pcf',\n",
    "       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe',\n",
    "       'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt',\n",
    "       'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "       'divyield']\n",
    "\n",
    "## XX per share characteristics: IN Online Appendix A.2, BHL states that they \"consider another twenty-six \n",
    "# fundamental values per share derived from these financial ratios\"\n",
    "# We recover these features from their persudo-data shared in RFS code & data\n",
    "# See the data they shared: \"/Earnings Forecasts/SampleFigure1.csv\". Columns 'BU' to 'CR', totaling 24\n",
    "# I add \"sales_p\" & \"invcap_p\" to make it 26\n",
    "per_share_chars = ['dividend_p','BE_p','Liability_p','cur_liability_p','LT_debt_p',\n",
    "                   'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', \n",
    "                   'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p',\n",
    "                   'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p',\n",
    "                   'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p','ptpm_p'\n",
    "                  ]\n",
    "\n",
    "df['dividend_p'] = df['divyield'] * df['prc']\n",
    "df['BE_p'] = df['bm'] * df['prc'] # book-equity\n",
    "df['Liability_p'] = df['de_ratio'] * df['BE_p'] # Total Debt\n",
    "df['cur_liability_p'] = df['curr_debt'] * df['Liability_p']\n",
    "df['LT_debt_p'] = df['lt_debt'] * df['Liability_p']\n",
    "df['cash_p'] = df['cash_lt'] * df['Liability_p']\n",
    "df['total_asset_p'] = df['Liability_p'] / df['debt_at']\n",
    "df['tot_debt_p'] = df['debt_assets'] * df['total_asset_p']\n",
    "df['accrual_p'] = df['accrual'] * df['total_asset_p']\n",
    "df['EBIT_p'] = df['debt_ebitda'] / df['tot_debt_p']\n",
    "df['cur_asset_p'] = df['curr_ratio']*df['cur_liability_p']\n",
    "df['pbda_p'] = df['profit_lct'] * df['cur_liability_p'] # Operating Income before D&A\n",
    "df['ocf_p'] = df['ocf_lct'] * df['cur_liability_p'] # Operating Cash Flow\n",
    "df['inventory_p'] = df['invt_act'] * df['cur_asset_p']\n",
    "df['receivables_p'] = df['rect_act'] * df['cur_asset_p']\n",
    "df['Cur_debt_p'] = df['short_debt'] * df['total_asset_p'] # Short-term Debt\n",
    "df['interest_p'] = df['int_totdebt'] * df['tot_debt_p']\n",
    "df['fcf_ocf_p'] = df['fcf_ocf'] * df['ocf_p'] # Free Cash Flow\n",
    "df['evm_p'] = df['evm'] * df['EBIT_p'] # Multiple of Enterprise Value\n",
    "\n",
    "## ADD by YANDI ##\n",
    "df['sales_p'] = df['sale_equity'] * df['BE_p'] # Sales\n",
    "df['invcap_p'] = df['debt_invcap'] / df['LT_debt_p'] # Invested Capital\n",
    "\n",
    "## Recover theirs\n",
    "df['c_equity_p'] = df['equity_invcap'] * df['invcap_p'] # Common Equity\n",
    "df['rd_p'] = df['rd_sale'] * df['sales_p'] # R&D\n",
    "df['opmad_p'] = df['opmad'] * df['sales_p'] # Operating Income After Depreciation\n",
    "df['gpm_p'] = df['gpm']  * df['sales_p'] # Gross Profit\n",
    "df['ptpm_p'] = df['ptpm']  * df['sales_p'] # Pretax Income\n",
    "\n",
    "df.replace([-np.inf, np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cce3543-8fa8-4a0e-9d3d-fca696676d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 93/93 [05:20<00:00,  3.44s/it]\n",
      "100%|███████████████████████████████████████████| 93/93 [00:11<00:00,  8.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Your existing code here\n",
    "for v in tqdm(ratio_chars+per_share_chars):\n",
    "    df[v] = df.groupby(['YearMonth','fama49'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "for v in tqdm(ratio_chars+per_share_chars):\n",
    "    df[v] = df.groupby(['YearMonth'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a05aa8b-eabc-4d97-9e97-0006b52e9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Macro Data\n",
    "RGDP = pd.read_excel('./data/Macro/RGDP.xlsx').set_index('DATE')\n",
    "RGDP = RGDP.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "RGDP.index = pd.date_range(start='1965-11', end='2024-04', freq='M')\n",
    "\n",
    "RCON = pd.read_excel('./data/Macro/RCON.xlsx').set_index('DATE')\n",
    "RCON = RCON.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "RCON.index = pd.date_range(start='1965-11', end='2024-04', freq='M')\n",
    "\n",
    "INDPROD = pd.read_excel('./data/Macro/INDPROD.xlsx').set_index('DATE')\n",
    "INDPROD = INDPROD.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "INDPROD.index = pd.date_range(start='1962-11', end='2024-03', freq='M')\n",
    "\n",
    "UNEMP = pd.read_excel('./data/Macro/UNEMP.xlsx').set_index('DATE')\n",
    "UNEMP = UNEMP['RUC24Q1'].dropna()\n",
    "UNEMP.index = pd.date_range(start='1948-01', end='2024-02', freq='M')\n",
    "## LAG one month, we can only observe last month UNEMP\n",
    "UNEMP = UNEMP.shift(1)\n",
    "\n",
    "macro = pd.DataFrame({'RGDP':RGDP,'RCON':RCON,'INDPROD':INDPROD,'UNEMP':UNEMP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73ff8dc7-40dd-494c-874b-5b9714e01dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(macro, left_on='YearMonth', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "889f421f-eae6-483b-88d9-7374fef3bf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EPS_ana_x', 'EPS_true_x', 'EPS_true_l1_x', 'ANNDATS_x', 'ANNDATS_l1_x', 'horizon_q1', 'permno', 'YearMonth', 'EPS_ana_y', 'EPS_true_y', 'EPS_true_l1_y', 'ANNDATS_y', 'ANNDATS_l1_y', 'horizon_q2', 'EPS_ana', 'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1', 'horizon_q3', 'STATPERS_x', 'FPEDATS', 'EPS_ana_y1', 'EPS_true_y1', 'EPS_true_l1_y1', 'ANNDATS_y1', 'ANNDATS_l1_y1', 'horizon_a1', 'STATPERS_y', 'EPS_ana_y2', 'EPS_true_y2', 'EPS_true_l1_y2', 'ANNDATS_y2', 'ANNDATS_l1_y2', 'horizon_a2', 'siccd', 'ret', 'prc', 'bh1m', 'shrout', 'ME', 'prc_l1', 'gvkey', 'adate', 'qdate', 'public_date', 'CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'pe_inc', 'ps', 'pcf', 'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt', 'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at', 'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct', 'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets', 'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio', 'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn', 'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc', 'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing', 'divyield', 'PEG_1yrforward', 'PEG_ltgforward', 'TICKER', 'cusip', 'datadate', 'sich', 'sic', 'fama49', 'dividend_p', 'BE_p', 'Liability_p', 'cur_liability_p', 'LT_debt_p', 'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', 'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p', 'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p', 'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p', 'ptpm_p', 'RGDP', 'RCON', 'INDPROD', 'UNEMP']\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54b2338c-a275-484f-9ce7-8454f9424c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_chars = ['CAPEI', 'bm',\n",
    "       'evm', 'pe_exi', 'pe_inc', 'ps', 'pcf',\n",
    "       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe',\n",
    "       'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt',\n",
    "       'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "       'divyield']\n",
    "\n",
    "per_share_chars = ['dividend_p','BE_p','Liability_p','cur_liability_p','LT_debt_p',\n",
    "                  'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', \n",
    "                   'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p',\n",
    "                   'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p',\n",
    "                   'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p','ptpm_p'\n",
    "                  ]\n",
    "\n",
    "macro_chars = ['RGDP', 'RCON', 'INDPROD', 'UNEMP']\n",
    "\n",
    "fundamental_chars = ['ret', 'prc',\n",
    "                    'EPS_true_l1_y1'\n",
    "                    ]\n",
    "\n",
    "analyst_chars = ['EPS_ana_y1','EPS_ana_y2']\n",
    "\n",
    "targets = ['EPS_true_y1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3ec8d44-b0a8-4965-9130-e82dbfe99b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lag one month information ###\n",
    "### Except for analyst forecasts\n",
    "df.sort_values(by=['permno', 'YearMonth'], inplace=True)\n",
    "vars_lag = ratio_chars + per_share_chars + macro_chars + fundamental_chars\n",
    "df[vars_lag] = df.groupby('permno')[vars_lag].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7d667-85d4-4668-b662-7f45eec4a28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████▊   | 89/96 [17:11<00:13,  1.93s/it]"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ## FillNA with Industry Median\n",
    "fillNA = ratio_chars + per_share_chars + fundamental_chars\n",
    "for v in tqdm(fillNA):\n",
    "    df[v] = df.groupby(['YearMonth','fama49'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))\n",
    "## In case some characteristics are all NA in some industry\n",
    "for v in tqdm(fillNA + macro_chars):\n",
    "    df[v] = df.groupby(['YearMonth'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb574b5-ed49-4eda-8da9-1cddfa838b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df[(df['YearMonth'] >= '1984-01-01') & (df['YearMonth'] <= '2019-12-31')].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39713325-4cfd-40ca-96a8-abae607501fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorization period-by-period\n",
    "cols = ratio_chars + per_share_chars + fundamental_chars\n",
    "df_tmp[cols] = df_tmp.groupby('YearMonth',group_keys=False)[cols]\\\n",
    "                             .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399074ec-e697-40b5-a88b-c7cba4c11106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.to_csv('./data/Results/df_train_a1_FU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb697da2-6a3a-4977-be4a-062a1fa71bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
