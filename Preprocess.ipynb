{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import *\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crsp = pd.read_parquet('./data/WRDS/crsp_m.parquet')\n",
    "crsp['prc'] = abs(crsp['prc'])\n",
    "crsp['ME'] = (crsp['prc']) * crsp['shrout']\n",
    "crsp.sort_values(by=['permno','YearMonth'], inplace=True)\n",
    "crsp['bh1m'] = crsp.groupby('permno')['retadj'].shift(-1)\n",
    "crsp['prc_l1'] = crsp.groupby('permno')['prc'].shift(1)\n",
    "crsp.duplicated(subset=['permno','YearMonth']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IBES actual\n",
    "EPS_true = pd.read_stata('./data/WRDS/EPS_unadjusted_actual_full.dta')\n",
    "EPS_true['YearMonth'] = EPS_true['ANNDATS'] + MonthEnd(0)\n",
    "EPS_true['EPS_true'] = EPS_true['VALUE']\n",
    "\n",
    "# Last EPS\n",
    "EPS_true_qtr = EPS_true[EPS_true['PDICITY'] == 'QTR'].sort_values(by=['TICKER','PENDS'])\n",
    "EPS_true_ann = EPS_true[EPS_true['PDICITY'] == 'ANN'].sort_values(by=['TICKER','PENDS'])\n",
    "\n",
    "EPS_true_qtr['EPS_true_l1'] = EPS_true_qtr.groupby('TICKER')['EPS_true'].shift(1)\n",
    "EPS_true_qtr['ANNDATS_l1'] = EPS_true_qtr.groupby('TICKER')['ANNDATS'].shift(1)\n",
    "\n",
    "EPS_true_ann['EPS_true_l1'] = EPS_true_ann.groupby\n",
    "EPS_true_ann['ANNDATS_l1'] = EPS_true_ann.groupby('TICKER')['ANNDATS'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud Computing Required Seperate File Used (Preprocess_EPS.ipynb) \n",
    "\n",
    "# # Step 1: Read the .dta file\n",
    "# df = pd.read_stata(\"./data/WRDS/EPS_summary.dta\")\n",
    "\n",
    "# # Step 2 (optional): Inspect the data\n",
    "# print(df.head())\n",
    "\n",
    "# # Step 3: Save as Parquet\n",
    "# df.to_parquet(\"./data/WRDS/EPS_summary.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IBES consensus\n",
    "consensus = pd.read_parquet('./data/WRDS/EPS_summary.parquet')\n",
    "\n",
    "consensus['YearMonth'] = consensus['STATPERS'] + MonthEnd(0)\n",
    "consensus['EPS_ana'] = consensus['MEANEST']\n",
    "\n",
    "# Merge with Actual\n",
    "consensus_quarter = consensus[consensus.FPI.isin(['6','7','8'])].copy()\n",
    "consensus_annual = consensus[consensus.FPI.isin(['1','2'])].copy()\n",
    "\n",
    "consensus_quarter = consensus_quarter.merge(\n",
    "    EPS_true_qtr[['TICKER','PENDS','EPS_true','ANNDATS','ANNDATS_l1','EPS_true_l1']], \n",
    "    left_on=['TICKER','FPEDATS'], \n",
    "    right_on=['TICKER','PENDS']\n",
    ")\n",
    "\n",
    "consensus_annual = consensus_annual.merge(\n",
    "    EPS_true_ann[['TICKER','PENDS','EPS_true','ANNDATS','ANNDATS_l1','EPS_true_l1']], \n",
    "    left_on=['TICKER','FPEDATS'], \n",
    "    right_on=['TICKER','PENDS']\n",
    ")\n",
    "\n",
    "consensus = pd.concat([consensus_quarter, consensus_annual], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TICKER     CUSIP OFTIC               CNAME   STATPERS MEASURE FISCALP FPI  \\\n",
      "0   0000  87482X10  TLMR  TALMER BANCORP INC 2014-04-17     EPS     QTR   6   \n",
      "1   0000  87482X10  TLMR  TALMER BANCORP INC 2014-05-15     EPS     QTR   6   \n",
      "2   0000  87482X10  TLMR  TALMER BANCORP INC 2014-06-19     EPS     QTR   6   \n",
      "3   0000  87482X10  TLMR  TALMER BANCORP INC 2014-07-17     EPS     QTR   6   \n",
      "4   0000  87482X10  TLMR  TALMER BANCORP INC 2014-04-17     EPS     QTR   7   \n",
      "\n",
      "  ESTFLAG CURCODE  ...  LOWEST  USFIRM    FPEDATS  YearMonth  EPS_ana  \\\n",
      "0       P     USD  ...    0.07     1.0 2014-03-31 2014-04-30     0.08   \n",
      "1       P     USD  ...    0.12     1.0 2014-06-30 2014-05-31     0.13   \n",
      "2       P     USD  ...    0.12     1.0 2014-06-30 2014-06-30     0.13   \n",
      "3       P     USD  ...    0.12     1.0 2014-06-30 2014-07-31     0.13   \n",
      "4       P     USD  ...    0.10     1.0 2014-06-30 2014-04-30     0.12   \n",
      "\n",
      "       PENDS  EPS_true    ANNDATS  ANNDATS_l1 EPS_true_l1  \n",
      "0 2014-03-31      0.12 2014-05-06  2014-02-14         NaN  \n",
      "1 2014-06-30      0.27 2014-08-06  2014-05-06        0.12  \n",
      "2 2014-06-30      0.27 2014-08-06  2014-05-06        0.12  \n",
      "3 2014-06-30      0.27 2014-08-06  2014-05-06        0.12  \n",
      "4 2014-06-30      0.27 2014-08-06  2014-05-06        0.12  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Index(['TICKER', 'CUSIP', 'OFTIC', 'CNAME', 'STATPERS', 'MEASURE', 'FISCALP',\n",
      "       'FPI', 'ESTFLAG', 'CURCODE', 'NUMEST', 'NUMUP', 'NUMDOWN', 'MEDEST',\n",
      "       'MEANEST', 'STDEV', 'HIGHEST', 'LOWEST', 'USFIRM', 'FPEDATS',\n",
      "       'YearMonth', 'EPS_ana', 'PENDS', 'EPS_true', 'ANNDATS', 'ANNDATS_l1',\n",
      "       'EPS_true_l1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(consensus.head())\n",
    "print(consensus.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CRSP-IBES link table\n",
    "iclink = pd.read_csv('./data/WRDS/iclink_WRDS.csv')\n",
    "iclink.columns = ['ticker','permno','ncusip','sdate','edate','score']\n",
    "iclink['sdate'] = pd.to_datetime(iclink['sdate'])\n",
    "iclink['edate'] = pd.to_datetime(iclink['edate'])\n",
    "iclink.dropna(subset=['permno'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process by Q and A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Manage forecast and actual\n",
    "q1 = consensus[consensus['FPI'] == '6'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']\n",
    "                                       ].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "# ICLINK\n",
    "q1 = q1.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "q1 = q1[(q1['STATPERS'] >= q1['sdate']) & (q1['STATPERS'] <= q1['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "q1['ANN_m'] = q1['ANNDATS'] + MonthEnd(0)\n",
    "q1 = q1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'],\n",
    "              right_on=['permno', 'YearMonth'])\n",
    "q1['EPS_true_l1'] = q1.apply(\n",
    "    lambda row: row['EPS_true_l1'] / row['cfacshr'] if row['cfacshr'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "q1.drop(columns=['YearMonth', 'cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "q1['ANN_m'] = q1['ANNDATS_l1'] + MonthEnd(0)\n",
    "q1 = q1.merge(crsp[['permno', 'YearMonth', 'cfacshr']], \n",
    "              left_on=['permno', 'ANN_m'],\n",
    "              right_on=['permno', 'YearMonth'],\n",
    "              how='left')\n",
    "q1['EPS_true_l1'] = q1['EPS_true_l1'] / q1['cfacshr']\n",
    "q1.drop(columns=['YearMonth', 'cfacshr', 'sdate', 'edate', 'ANN_m'], inplace=True)\n",
    "\n",
    "# Today's adjustment\n",
    "q1['YearMonth'] = q1['STATPERS'] + MonthEnd(0)\n",
    "q1 = q1.merge(crsp[['permno', 'YearMonth', 'cfacshr', 'ncusip']], \n",
    "              on=['permno', 'YearMonth'])\n",
    "q1['EPS_true'] = q1['EPS_true'] * q1['cfacshr']\n",
    "q1['EPS_true_l1'] = q1['EPS_true_l1'] * q1['cfacshr']\n",
    "q1 = q1[q1['ncusip'] == q1['CUSIP']]\n",
    "q1.drop(columns=['cfacshr', 'ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = consensus[consensus['FPI'] == '7'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']\n",
    "                                       ].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "# ICLINK\n",
    "q2 = q2.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "\n",
    "q2 = q2[(q2['STATPERS']>=q2['sdate']) & (q2['STATPERS']<=q2['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "q2['ANN_m'] = q2['ANNDATS'] + MonthEnd(0)\n",
    "q2 = q2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "             )\n",
    "q2['EPS_true'] = q2['EPS_true']/q2['cfacshr']\n",
    "q2.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "q2['ANN_m'] = q2['ANNDATS_l1'] + MonthEnd(0)\n",
    "q2 = q2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "             how='left'\n",
    "             )\n",
    "\n",
    "q2['EPS_true_l1'] = q2.apply(\n",
    "    lambda row: row['EPS_true_l1'] / row['cfacshr'] if row['cfacshr'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "q2.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "q2['YearMonth'] = q2['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "q2 = q2.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "q2['EPS_true'] = q2['EPS_true'] * q2['cfacshr']\n",
    "q2['EPS_true_l1'] = q2['EPS_true_l1'] * q2['cfacshr']\n",
    "q2 = q2[q2['ncusip']==q2['CUSIP']]\n",
    "q2.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = consensus[consensus['FPI']=='8'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                         'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1']\n",
    "                                       ].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "# ICLINK\n",
    "q3 = q3.merge(iclink[['ticker', 'permno', 'sdate', 'edate', 'score']], \n",
    "              left_on='TICKER', right_on='ticker')\n",
    "\n",
    "q3 = q3[(q3['STATPERS']>=q3['sdate']) & (q3['STATPERS']<=q3['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "q3['ANN_m'] = q3['ANNDATS'] + MonthEnd(0)\n",
    "q3 = q3.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              # how='left'\n",
    "             )\n",
    "# q3['cfacshr'] = q3.groupby('permno')['cfacshr'].ffill()\n",
    "q3['EPS_true'] = q3['EPS_true']/q3['cfacshr']\n",
    "q3.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "q3['ANN_m'] = q3['ANNDATS_l1'] + MonthEnd(0)\n",
    "q3 = q3.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              how='left'\n",
    "             )\n",
    "\n",
    "q3['EPS_true_l1'] = q3.apply(\n",
    "    lambda row: row['EPS_true_l1'] / row['cfacshr'] if row['cfacshr'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "q3.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "q3['YearMonth'] = q3['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "\n",
    "q3 = q3.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "q3['EPS_true'] = q3['EPS_true'] * q3['cfacshr']\n",
    "q3['EPS_true_l1'] = q3['EPS_true_l1'] * q3['cfacshr']\n",
    "q3 = q3[q3['CUSIP']==q3['ncusip']]\n",
    "q3.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a1 = consensus[consensus['FPI']=='1'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                       'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1',\n",
    "                                      ]].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "# ICLINK\n",
    "a1 = a1.merge(iclink[['ticker','permno','sdate','edate','score']], \n",
    "              left_on=['TICKER'],\n",
    "              right_on=['ticker'])\n",
    "a1 = a1[(a1['STATPERS']>=a1['sdate']) & (a1['STATPERS']<=a1['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "a1['ANN_m'] = a1['ANNDATS'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "             )\n",
    "a1['EPS_true'] = a1['EPS_true']/a1['cfacshr']\n",
    "a1.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "a1['ANN_m'] = a1['ANNDATS_l1'] + MonthEnd(0)\n",
    "a1 = a1.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              how='left'\n",
    "             )\n",
    "# Ensure cfacshr is numeric\n",
    "a1['cfacshr'] = pd.to_numeric(a1['cfacshr'], errors='coerce')\n",
    "a1['EPS_true_l1'] = pd.to_numeric(a1['EPS_true_l1'], errors='coerce')\n",
    "\n",
    "# Then perform the division\n",
    "a1['EPS_true_l1'] = a1['EPS_true_l1'] / a1['cfacshr']\n",
    "a1.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "a1['YearMonth'] = a1['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "print(a1.duplicated(subset=['permno','STATPERS']).sum())\n",
    "\n",
    "a1 = a1.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "a1['EPS_true'] = a1['EPS_true'] * a1['cfacshr']\n",
    "a1['EPS_true_l1'] = a1['EPS_true_l1'] * a1['cfacshr']\n",
    "a1 = a1[a1['CUSIP'] == a1['ncusip']]\n",
    "a1.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a2 = consensus[consensus['FPI']=='2'][['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana',\n",
    "                                       'EPS_true', 'EPS_true_l1', 'ANNDATS', 'ANNDATS_l1',\n",
    "                                      ]].drop_duplicates(subset=['TICKER', 'STATPERS']).copy()\n",
    "\n",
    "# ICLINK\n",
    "a2 = a2.merge(iclink[['ticker','permno','sdate','edate','score']], \n",
    "              left_on=['TICKER'],\n",
    "              right_on=['ticker'])\n",
    "a2 = a2[(a2['STATPERS'] >= a2['sdate']) & (a2['STATPERS'] <= a2['edate'])]\n",
    "\n",
    "# ANN month cfacshr\n",
    "a2['ANN_m'] = a2['ANNDATS'] + MonthEnd(0)\n",
    "a2 = a2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'])\n",
    "a2['EPS_true'] = a2['EPS_true'] / a2['cfacshr']\n",
    "a2.drop(columns=['YearMonth','cfacshr'], inplace=True)\n",
    "\n",
    "# Last ANN month cfacshr\n",
    "a2['ANN_m'] = a2['ANNDATS_l1'] + MonthEnd(0)\n",
    "a2 = a2.merge(crsp[['permno','YearMonth','cfacshr']], \n",
    "              left_on=['permno','ANN_m'],\n",
    "              right_on=['permno','YearMonth'],\n",
    "              how='left')\n",
    "# Ensure cfacshr is numeric\n",
    "a2['cfacshr'] = pd.to_numeric(a2['cfacshr'], errors='coerce')\n",
    "a2['EPS_true_l1'] = pd.to_numeric(a2['EPS_true_l1'], errors='coerce')\n",
    "\n",
    "# Perform the division\n",
    "a2['EPS_true_l1'] = a2['EPS_true_l1'] / a2['cfacshr']\n",
    "a2.drop(columns=['YearMonth','cfacshr','sdate','edate','ANN_m'], inplace=True)\n",
    "\n",
    "a2['YearMonth'] = a2['STATPERS'] + MonthEnd(0)\n",
    "\n",
    "print(a2.duplicated(subset=['permno','STATPERS']).sum())\n",
    "\n",
    "a2 = a2.merge(crsp[['permno','YearMonth','cfacshr','ncusip']], on=['permno','YearMonth'])\n",
    "# Adjust to today cfacshr\n",
    "a2['EPS_true'] = a2['EPS_true'] * a2['cfacshr']\n",
    "a2['EPS_true_l1'] = a2['EPS_true_l1'] * a2['cfacshr']\n",
    "# cusip == ncusip\n",
    "a2 = a2[a2['CUSIP'] == a2['ncusip']].copy()\n",
    "a2.drop(columns=['cfacshr','ncusip'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1['EPS_ana'] = q1.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "q1['EPS_true'] = q1.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "q1.rename(columns={'EPS_true_l1':'EPS_true_l1_q1',\n",
    "                   'EPS_true':'EPS_true_q1',\n",
    "                   'EPS_ana':'EPS_ana_q1',\n",
    "                   'ANNDATS':'ANNDATS_q1','ANNDATS_l1':'ANNDATS_l1_q1',\n",
    "                  }, \n",
    "          inplace=True)\n",
    "\n",
    "q2['EPS_ana'] = q2.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "q2['EPS_true'] = q2.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "q2.rename(columns={'EPS_true_l1':'EPS_true_l1_q2',\n",
    "                   'EPS_true':'EPS_true_q2',\n",
    "                   'EPS_ana':'EPS_ana_q2',\n",
    "                   'ANNDATS':'ANNDATS_q2',\n",
    "                  }, \n",
    "          inplace=True)\n",
    "\n",
    "q3['EPS_ana'] = q3.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "q3['EPS_true'] = q3.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "q3.rename(columns={'EPS_true_l1':'EPS_true_l1_q3',\n",
    "                   'EPS_true':'EPS_true_q3',\n",
    "                   'EPS_ana':'EPS_ana_q3','ANNDATS':'ANNDATS_q3',\n",
    "                  }, \n",
    "          inplace=True)\n",
    "\n",
    "a1['EPS_ana'] = a1.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a1['EPS_true'] = a1.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a1.rename(columns={'EPS_true_l1':'EPS_true_l1_y1',\n",
    "                   'EPS_true':'EPS_true_y1','EPS_ana':'EPS_ana_y1',\n",
    "                   'ANNDATS':'ANNDATS_y1','ANNDATS_l1':'ANNDATS_l1_y1',\n",
    "                  }, \n",
    "          inplace=True)\n",
    "\n",
    "a2['EPS_ana'] = a2.groupby('YearMonth',group_keys=False)[f'EPS_ana']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a2['EPS_true'] = a2.groupby('YearMonth',group_keys=False)[f'EPS_true']\\\n",
    "               .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))\n",
    "a2.rename(columns={'EPS_true_l1':'EPS_true_l1_y2',\n",
    "                   'EPS_true':'EPS_true_y2',\n",
    "                   'EPS_ana':'EPS_ana_y2','ANNDATS':'ANNDATS_y2',\n",
    "                  }, \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TICKER   STATPERS     CUSIP  EPS_ana_q1  EPS_true_q1  EPS_true_l1_q1  \\\n",
      "0   0000 2014-04-17  87482X10        0.08         0.12             NaN   \n",
      "1   0000 2014-05-15  87482X10        0.13         0.27            0.12   \n",
      "2   0000 2014-06-19  87482X10        0.13         0.27            0.12   \n",
      "3   0000 2014-07-17  87482X10        0.13         0.27            0.12   \n",
      "4   0000 2014-08-14  87482X10        0.25         0.26            0.27   \n",
      "\n",
      "  ANNDATS_q1 ANNDATS_l1_q1 ticker   permno  score  YearMonth  \n",
      "0 2014-05-06    2014-02-14   0000  14471.0      1 2014-04-30  \n",
      "1 2014-08-06    2014-05-06   0000  14471.0      1 2014-05-31  \n",
      "2 2014-08-06    2014-05-06   0000  14471.0      1 2014-06-30  \n",
      "3 2014-08-06    2014-05-06   0000  14471.0      1 2014-07-31  \n",
      "4 2014-11-04    2014-08-06   0000  14471.0      1 2014-08-31  \n",
      "Index(['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana_q1', 'EPS_true_q1',\n",
      "       'EPS_true_l1_q1', 'ANNDATS_q1', 'ANNDATS_l1_q1', 'ticker', 'permno',\n",
      "       'score', 'YearMonth'],\n",
      "      dtype='object')\n",
      "  TICKER   STATPERS     CUSIP  EPS_ana_q2  EPS_true_q2  EPS_true_l1_q2  \\\n",
      "0   0000 2014-04-17  87482X10        0.12         0.27            0.12   \n",
      "1   0000 2014-05-15  87482X10        0.17         0.26            0.27   \n",
      "2   0000 2014-06-19  87482X10        0.18         0.26            0.27   \n",
      "3   0000 2014-07-17  87482X10        0.18         0.26            0.27   \n",
      "4   0000 2014-08-14  87482X10        0.17         0.16            0.26   \n",
      "\n",
      "  ANNDATS_q2 ANNDATS_l1 ticker   permno  score  YearMonth  \n",
      "0 2014-08-06 2014-05-06   0000  14471.0      1 2014-04-30  \n",
      "1 2014-11-04 2014-08-06   0000  14471.0      1 2014-05-31  \n",
      "2 2014-11-04 2014-08-06   0000  14471.0      1 2014-06-30  \n",
      "3 2014-11-04 2014-08-06   0000  14471.0      1 2014-07-31  \n",
      "4 2015-01-30 2014-11-04   0000  14471.0      1 2014-08-31  \n",
      "Index(['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana_q2', 'EPS_true_q2',\n",
      "       'EPS_true_l1_q2', 'ANNDATS_q2', 'ANNDATS_l1', 'ticker', 'permno',\n",
      "       'score', 'YearMonth'],\n",
      "      dtype='object')\n",
      "  TICKER   STATPERS     CUSIP  EPS_ana_q3  EPS_true_q3  EPS_true_l1_q3  \\\n",
      "0   0000 2014-04-17  87482X10        0.15         0.26            0.27   \n",
      "1   0000 2014-05-15  87482X10        0.17         0.16            0.26   \n",
      "2   0000 2014-06-19  87482X10        0.17         0.16            0.26   \n",
      "3   0000 2014-07-17  87482X10        0.17         0.16            0.26   \n",
      "4   0000 2014-08-14  87482X10        0.19         0.12            0.16   \n",
      "\n",
      "  ANNDATS_q3 ANNDATS_l1 ticker   permno  score  YearMonth  \n",
      "0 2014-11-04 2014-08-06   0000  14471.0      1 2014-04-30  \n",
      "1 2015-01-30 2014-11-04   0000  14471.0      1 2014-05-31  \n",
      "2 2015-01-30 2014-11-04   0000  14471.0      1 2014-06-30  \n",
      "3 2015-01-30 2014-11-04   0000  14471.0      1 2014-07-31  \n",
      "4 2015-04-30 2015-01-30   0000  14471.0      1 2014-08-31  \n",
      "Index(['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana_q3', 'EPS_true_q3',\n",
      "       'EPS_true_l1_q3', 'ANNDATS_q3', 'ANNDATS_l1', 'ticker', 'permno',\n",
      "       'score', 'YearMonth'],\n",
      "      dtype='object')\n",
      "  TICKER   STATPERS     CUSIP  EPS_ana_y1  EPS_true_y1  EPS_true_l1_y1  \\\n",
      "0   0000 2014-04-17  87482X10        0.52         1.21             NaN   \n",
      "1   0000 2014-05-15  87482X10        0.56         1.21             NaN   \n",
      "2   0000 2014-06-19  87482X10        0.56         1.21             NaN   \n",
      "3   0000 2014-07-17  87482X10        0.56         1.21             NaN   \n",
      "4   0000 2014-08-14  87482X10        1.18         1.21             NaN   \n",
      "\n",
      "  ANNDATS_y1 ANNDATS_l1_y1 ticker   permno  score  YearMonth  \n",
      "0 2015-01-30    2014-02-14   0000  14471.0      1 2014-04-30  \n",
      "1 2015-01-30    2014-02-14   0000  14471.0      1 2014-05-31  \n",
      "2 2015-01-30    2014-02-14   0000  14471.0      1 2014-06-30  \n",
      "3 2015-01-30    2014-02-14   0000  14471.0      1 2014-07-31  \n",
      "4 2015-01-30    2014-02-14   0000  14471.0      1 2014-08-31  \n",
      "Index(['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana_y1', 'EPS_true_y1',\n",
      "       'EPS_true_l1_y1', 'ANNDATS_y1', 'ANNDATS_l1_y1', 'ticker', 'permno',\n",
      "       'score', 'YearMonth'],\n",
      "      dtype='object')\n",
      "  TICKER   STATPERS     CUSIP  EPS_ana_y2  EPS_true_y2  EPS_true_l1_y2  \\\n",
      "0   0000 2014-04-17  87482X10        0.85         1.02             NaN   \n",
      "1   0000 2014-05-15  87482X10        0.87         1.02             NaN   \n",
      "2   0000 2014-06-19  87482X10        0.88         1.02             NaN   \n",
      "3   0000 2014-07-17  87482X10        0.88         1.02             NaN   \n",
      "4   0000 2014-08-14  87482X10        0.90         1.02             NaN   \n",
      "\n",
      "  ANNDATS_y2 ANNDATS_l1 ticker   permno  score  YearMonth  \n",
      "0 2016-01-26 2015-01-30   0000  14471.0      1 2014-04-30  \n",
      "1 2016-01-26 2015-01-30   0000  14471.0      1 2014-05-31  \n",
      "2 2016-01-26 2015-01-30   0000  14471.0      1 2014-06-30  \n",
      "3 2016-01-26 2015-01-30   0000  14471.0      1 2014-07-31  \n",
      "4 2016-01-26 2015-01-30   0000  14471.0      1 2014-08-31  \n",
      "Index(['TICKER', 'STATPERS', 'CUSIP', 'EPS_ana_y2', 'EPS_true_y2',\n",
      "       'EPS_true_l1_y2', 'ANNDATS_y2', 'ANNDATS_l1', 'ticker', 'permno',\n",
      "       'score', 'YearMonth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(q1.head())\n",
    "print(q1.columns)\n",
    "print(q2.head())\n",
    "print(q2.columns)\n",
    "print(q3.head())\n",
    "print(q3.columns)\n",
    "print(a1.head())\n",
    "print(a1.columns)\n",
    "print(a2.head())\n",
    "print(a2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns\n",
    "q1_cleaned = q1.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])\n",
    "q2_cleaned = q2.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])\n",
    "q3_cleaned = q3.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])\n",
    "a1_cleaned = a1.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])\n",
    "a2_cleaned = a2.drop(columns=['TICKER', 'STATPERS', 'CUSIP', 'score', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EPS_ana_q1  EPS_true_q1  EPS_true_l1_q1 ANNDATS_q1 ANNDATS_l1_q1   permno  \\\n",
      "0        0.08         0.12             NaN 2014-05-06    2014-02-14  14471.0   \n",
      "1        0.13         0.27            0.12 2014-08-06    2014-05-06  14471.0   \n",
      "2        0.13         0.27            0.12 2014-08-06    2014-05-06  14471.0   \n",
      "3        0.13         0.27            0.12 2014-08-06    2014-05-06  14471.0   \n",
      "4        0.25         0.26            0.27 2014-11-04    2014-08-06  14471.0   \n",
      "\n",
      "   YearMonth  \n",
      "0 2014-04-30  \n",
      "1 2014-05-31  \n",
      "2 2014-06-30  \n",
      "3 2014-07-31  \n",
      "4 2014-08-31  \n",
      "Index(['EPS_ana_q1', 'EPS_true_q1', 'EPS_true_l1_q1', 'ANNDATS_q1',\n",
      "       'ANNDATS_l1_q1', 'permno', 'YearMonth'],\n",
      "      dtype='object')\n",
      "   EPS_ana_q2  EPS_true_q2  EPS_true_l1_q2 ANNDATS_q2 ANNDATS_l1   permno  \\\n",
      "0        0.12         0.27            0.12 2014-08-06 2014-05-06  14471.0   \n",
      "1        0.17         0.26            0.27 2014-11-04 2014-08-06  14471.0   \n",
      "2        0.18         0.26            0.27 2014-11-04 2014-08-06  14471.0   \n",
      "3        0.18         0.26            0.27 2014-11-04 2014-08-06  14471.0   \n",
      "4        0.17         0.16            0.26 2015-01-30 2014-11-04  14471.0   \n",
      "\n",
      "   YearMonth  \n",
      "0 2014-04-30  \n",
      "1 2014-05-31  \n",
      "2 2014-06-30  \n",
      "3 2014-07-31  \n",
      "4 2014-08-31  \n",
      "Index(['EPS_ana_q2', 'EPS_true_q2', 'EPS_true_l1_q2', 'ANNDATS_q2',\n",
      "       'ANNDATS_l1', 'permno', 'YearMonth'],\n",
      "      dtype='object')\n",
      "   EPS_ana_q3  EPS_true_q3  EPS_true_l1_q3 ANNDATS_q3 ANNDATS_l1   permno  \\\n",
      "0        0.15         0.26            0.27 2014-11-04 2014-08-06  14471.0   \n",
      "1        0.17         0.16            0.26 2015-01-30 2014-11-04  14471.0   \n",
      "2        0.17         0.16            0.26 2015-01-30 2014-11-04  14471.0   \n",
      "3        0.17         0.16            0.26 2015-01-30 2014-11-04  14471.0   \n",
      "4        0.19         0.12            0.16 2015-04-30 2015-01-30  14471.0   \n",
      "\n",
      "   YearMonth  \n",
      "0 2014-04-30  \n",
      "1 2014-05-31  \n",
      "2 2014-06-30  \n",
      "3 2014-07-31  \n",
      "4 2014-08-31  \n",
      "Index(['EPS_ana_q3', 'EPS_true_q3', 'EPS_true_l1_q3', 'ANNDATS_q3',\n",
      "       'ANNDATS_l1', 'permno', 'YearMonth'],\n",
      "      dtype='object')\n",
      "   EPS_ana_y1  EPS_true_y1  EPS_true_l1_y1 ANNDATS_y1 ANNDATS_l1_y1   permno  \\\n",
      "0        0.52         1.21             NaN 2015-01-30    2014-02-14  14471.0   \n",
      "1        0.56         1.21             NaN 2015-01-30    2014-02-14  14471.0   \n",
      "2        0.56         1.21             NaN 2015-01-30    2014-02-14  14471.0   \n",
      "3        0.56         1.21             NaN 2015-01-30    2014-02-14  14471.0   \n",
      "4        1.18         1.21             NaN 2015-01-30    2014-02-14  14471.0   \n",
      "\n",
      "   YearMonth  \n",
      "0 2014-04-30  \n",
      "1 2014-05-31  \n",
      "2 2014-06-30  \n",
      "3 2014-07-31  \n",
      "4 2014-08-31  \n",
      "Index(['EPS_ana_y1', 'EPS_true_y1', 'EPS_true_l1_y1', 'ANNDATS_y1',\n",
      "       'ANNDATS_l1_y1', 'permno', 'YearMonth'],\n",
      "      dtype='object')\n",
      "   EPS_ana_y2  EPS_true_y2  EPS_true_l1_y2 ANNDATS_y2 ANNDATS_l1   permno  \\\n",
      "0        0.85         1.02             NaN 2016-01-26 2015-01-30  14471.0   \n",
      "1        0.87         1.02             NaN 2016-01-26 2015-01-30  14471.0   \n",
      "2        0.88         1.02             NaN 2016-01-26 2015-01-30  14471.0   \n",
      "3        0.88         1.02             NaN 2016-01-26 2015-01-30  14471.0   \n",
      "4        0.90         1.02             NaN 2016-01-26 2015-01-30  14471.0   \n",
      "\n",
      "   YearMonth  \n",
      "0 2014-04-30  \n",
      "1 2014-05-31  \n",
      "2 2014-06-30  \n",
      "3 2014-07-31  \n",
      "4 2014-08-31  \n",
      "Index(['EPS_ana_y2', 'EPS_true_y2', 'EPS_true_l1_y2', 'ANNDATS_y2',\n",
      "       'ANNDATS_l1', 'permno', 'YearMonth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(q1_cleaned.head())\n",
    "print(q1_cleaned.columns)\n",
    "print(q2_cleaned.head())\n",
    "print(q2_cleaned.columns)\n",
    "print(q3_cleaned.head())\n",
    "print(q3_cleaned.columns)\n",
    "print(a1_cleaned.head())\n",
    "print(a1_cleaned.columns)\n",
    "print(a2_cleaned.head())\n",
    "print(a2_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge without suffixes\n",
    "ana_all = reduce(lambda x, y: pd.merge(x, y,\n",
    "                                       on=['permno', 'YearMonth'],\n",
    "                                       how='outer'),\n",
    "                 [q1_cleaned, q2_cleaned, q3_cleaned, a1_cleaned, a2_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ana_all.merge(crsp[['permno','YearMonth','siccd',\n",
    "                         'ret', 'prc', 'bh1m', 'shrout', 'ME','prc_l1'\n",
    "                        ]],\n",
    "                   on=['permno','YearMonth'], \n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Financial Ratios ####\n",
    "ratios = pd.read_stata('./data/WRDS/financial_ratio.dta')\n",
    "ratios['public_date'] = ratios['public_date'] + MonthEnd(0)\n",
    "ratios['gvkey'] = ratios['gvkey'].astype(float)\n",
    "\n",
    "#### COMUPSTAT ####\n",
    "compa = pd.read_parquet('./data/WRDS/compa.parquet')\n",
    "compa['gvkey'] = compa['gvkey'].astype(float)\n",
    "\n",
    "## SIC code from Compustat\n",
    "ratios = ratios.merge(compa[['gvkey','datadate','sich']], \n",
    "                     left_on = ['gvkey','adate'],\n",
    "                     right_on = ['gvkey','datadate'],\n",
    "                     how = 'left'\n",
    "                    )\n",
    "\n",
    "df = df.merge(ratios, \n",
    "              left_on=['permno','YearMonth'], \n",
    "              right_on=['permno','public_date'],\n",
    "              how = 'left'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FF49 Industry\n",
    "def zip_2_list(x):\n",
    "    tmp = []\n",
    "    for i, j in x:\n",
    "        tmp += list(range(i,j))\n",
    "    return tmp\n",
    "\n",
    "def fama_industry(sic, fama10):\n",
    "    for i in fama10.index:\n",
    "        if sic in fama10[i]:\n",
    "            return i\n",
    "    ## others\n",
    "    return 49\n",
    "\n",
    "# If sich is missing, use siccd from CRSP\n",
    "df['sic'] = np.where(df['sich'].isna(), df['siccd'], df['sich'])\n",
    "df['sic'] = df['sic'].astype(int)\n",
    "\n",
    "fama49 = pd.read_csv('./data/Other/Siccodes49.csv')\n",
    "fama49 = fama49.groupby('ff49').apply(lambda x: zip_2_list(zip(x.sic1, x.sic2+1)))\n",
    "\n",
    "_sic = df['sic'].unique()\n",
    "_sicff = pd.DataFrame(_sic).rename(columns={0:'sic'})\n",
    "_sicff['fama49'] = _sicff['sic'].apply(lambda x: fama_industry(x,fama49))\n",
    "\n",
    "df = pd.merge(df, _sicff, how='left', on=['sic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill NA with Industry Median\n",
    "## preprocess \n",
    "ratio_chars = ['CAPEI', 'bm',\n",
    "       'evm', 'pe_exi', 'pe_inc', 'ps', 'pcf',\n",
    "       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe',\n",
    "       'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt',\n",
    "       'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "       'divyield']\n",
    "\n",
    "## XX per share characteristics: IN Online Appendix A.2, BHL states that they \"consider another twenty-six \n",
    "# fundamental values per share derived from these financial ratios\"\n",
    "# We recover these features from their persudo-data shared in RFS code & data\n",
    "# See the data they shared: \"/Earnings Forecasts/SampleFigure1.csv\". Columns 'BU' to 'CR', totaling 24\n",
    "# I add \"sales_p\" & \"invcap_p\" to make it 26\n",
    "per_share_chars = ['dividend_p','BE_p','Liability_p','cur_liability_p','LT_debt_p',\n",
    "                  'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', \n",
    "                   'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p',\n",
    "                   'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p',\n",
    "                   'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p','ptpm_p'\n",
    "                  ]\n",
    "\n",
    "df['dividend_p'] = df['divyield'] * df['prc']\n",
    "df['BE_p'] = df['bm'] * df['prc'] # book-equity\n",
    "df['Liability_p'] = df['de_ratio'] * df['BE_p'] # Total Debt\n",
    "df['cur_liability_p'] = df['curr_debt'] * df['Liability_p']\n",
    "df['LT_debt_p'] = df['lt_debt'] * df['Liability_p']\n",
    "df['cash_p'] = df['cash_lt'] * df['Liability_p']\n",
    "df['total_asset_p'] = df['Liability_p'] / df['debt_at']\n",
    "df['tot_debt_p'] = df['debt_assets'] * df['total_asset_p']\n",
    "df['accrual_p'] = df['accrual'] * df['total_asset_p']\n",
    "df['EBIT_p'] = df['debt_ebitda'] / df['tot_debt_p']\n",
    "df['cur_asset_p'] = df['curr_ratio']*df['cur_liability_p']\n",
    "df['pbda_p'] = df['profit_lct'] * df['cur_liability_p'] # Operating Income before D&A\n",
    "df['ocf_p'] = df['ocf_lct'] * df['cur_liability_p'] # Operating Cash Flow\n",
    "df['inventory_p'] = df['invt_act'] * df['cur_asset_p']\n",
    "df['receivables_p'] = df['rect_act'] * df['cur_asset_p']\n",
    "df['Cur_debt_p'] = df['short_debt'] * df['total_asset_p'] # Short-term Debt\n",
    "df['interest_p'] = df['int_totdebt'] * df['tot_debt_p']\n",
    "df['fcf_ocf_p'] = df['fcf_ocf'] * df['ocf_p'] # Free Cash Flow\n",
    "df['evm_p'] = df['evm'] * df['EBIT_p'] # Multiple of Enterprise Value\n",
    "\n",
    "## ADD by YANDI ##\n",
    "df['sales_p'] = df['sale_equity'] * df['BE_p'] # Sales\n",
    "df['invcap_p'] = df['debt_invcap'] / df['LT_debt_p'] # Invested Capital\n",
    "\n",
    "## Recover theirs\n",
    "df['c_equity_p'] = df['equity_invcap'] * df['invcap_p'] # Common Equity\n",
    "df['rd_p'] = df['rd_sale'] * df['sales_p'] # R&D\n",
    "df['opmad_p'] = df['opmad'] * df['sales_p'] # Operating Income After Depreciation\n",
    "df['gpm_p'] = df['gpm']  * df['sales_p'] # Gross Profit\n",
    "df['ptpm_p'] = df['ptpm']  * df['sales_p'] # Pretax Income\n",
    "\n",
    "df.replace([-np.inf, np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 93/93 [03:05<00:00,  1.99s/it]\n",
      "100%|███████████████████████████████████████████| 93/93 [00:11<00:00,  8.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Your existing code here\n",
    "for v in tqdm(ratio_chars+per_share_chars):\n",
    "    df[v] = df.groupby(['YearMonth','fama49'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "for v in tqdm(ratio_chars+per_share_chars):\n",
    "    df[v] = df.groupby(['YearMonth'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Macro Data\n",
    "RGDP = pd.read_excel('./data/Macro/RGDP.xlsx').set_index('DATE')\n",
    "RGDP = RGDP.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "RGDP.index = pd.date_range(start='1965-11', end='2024-04', freq='M')\n",
    "\n",
    "RCON = pd.read_excel('./data/Macro/RCON.xlsx').set_index('DATE')\n",
    "RCON = RCON.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "RCON.index = pd.date_range(start='1965-11', end='2024-04', freq='M')\n",
    "\n",
    "INDPROD = pd.read_excel('./data/Macro/INDPROD.xlsx').set_index('DATE')\n",
    "INDPROD = INDPROD.apply(lambda x: np.log(x.dropna()).diff().iloc[-1], axis=0)\n",
    "INDPROD.index = pd.date_range(start='1962-11', end='2024-03', freq='M')\n",
    "\n",
    "UNEMP = pd.read_excel('./data/Macro/UNEMP.xlsx').set_index('DATE')\n",
    "UNEMP = UNEMP['RUC24Q1'].dropna()\n",
    "UNEMP.index = pd.date_range(start='1948-01', end='2024-02', freq='M')\n",
    "## LAG one month, we can only observe last month UNEMP\n",
    "UNEMP = UNEMP.shift(1)\n",
    "\n",
    "macro = pd.DataFrame({'RGDP':RGDP,'RCON':RCON,'INDPROD':INDPROD,'UNEMP':UNEMP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(macro, left_on='YearMonth', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_chars = ['CAPEI', 'bm',\n",
    "       'evm', 'pe_exi', 'pe_inc', 'ps', 'pcf',\n",
    "       'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe',\n",
    "       'roce', 'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'pretret_noa', 'pretret_earnat', 'GProf', 'equity_invcap',\n",
    "       'debt_invcap', 'totdebt_invcap', 'capital_ratio', 'int_debt',\n",
    "       'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "       'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "       'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "       'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'cash_conversion', 'inv_turn', 'at_turn',\n",
    "       'rect_turn', 'pay_turn', 'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "       'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "       'divyield']\n",
    "\n",
    "per_share_chars = ['dividend_p','BE_p','Liability_p','cur_liability_p','LT_debt_p',\n",
    "                  'cash_p', 'total_asset_p', 'tot_debt_p', 'accrual_p', 'EBIT_p', \n",
    "                   'cur_asset_p', 'pbda_p', 'ocf_p', 'inventory_p', 'receivables_p',\n",
    "                   'Cur_debt_p', 'interest_p', 'fcf_ocf_p', 'evm_p',\n",
    "                   'sales_p', 'invcap_p', 'c_equity_p', 'rd_p', 'opmad_p', 'gpm_p','ptpm_p'\n",
    "                  ]\n",
    "\n",
    "macro_chars = ['RGDP', 'RCON', 'INDPROD', 'UNEMP']\n",
    "\n",
    "fundamental_chars = ['ret', 'prc',\n",
    "                    'EPS_true_l1_q1','EPS_true_l1_q2','EPS_true_l1_q3',\n",
    "                    'EPS_true_l1_y1','EPS_true_l1_y2',\n",
    "                    ]\n",
    "\n",
    "analyst_chars = ['EPS_ana_q1','EPS_ana_q2','EPS_ana_q3','EPS_ana_y1','EPS_ana_y2']\n",
    "\n",
    "targets = ['EPS_true_q1', 'EPS_true_q2', 'EPS_true_q3', 'EPS_true_y1', 'EPS_true_y2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lag one month information ###\n",
    "### Except for analyst forecasts\n",
    "df.sort_values(by=['permno', 'YearMonth'], inplace=True)\n",
    "vars_lag = ratio_chars + per_share_chars + macro_chars + fundamental_chars\n",
    "df[vars_lag] = df.groupby('permno')[vars_lag].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [03:15<00:00,  1.95s/it]\n",
      "100%|█████████████████████████████████████████| 104/104 [00:12<00:00,  8.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ## FillNA with Industry Median\n",
    "fillNA = ratio_chars + per_share_chars + fundamental_chars\n",
    "for v in tqdm(fillNA):\n",
    "    df[v] = df.groupby(['YearMonth','fama49'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))\n",
    "## In case some characteristics are all NA in some industry\n",
    "for v in tqdm(fillNA + macro_chars):\n",
    "    df[v] = df.groupby(['YearMonth'], group_keys=False)[v].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df[(df['YearMonth'] >= '1984-01-01') & (df['YearMonth'] <= '2019-12-31')].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorization period-by-period\n",
    "cols = ratio_chars + per_share_chars + fundamental_chars\n",
    "df_tmp[cols] = df_tmp.groupby('YearMonth',group_keys=False)[cols]\\\n",
    "                             .transform(lambda x: x.clip(x.quantile(0.01),x.quantile(0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our working data\n",
    "df_tmp.to_parquet('./data/Results/df_train_new.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
